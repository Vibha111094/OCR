{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OCR_fun.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNfCxnMN3nRcEEHpx73SHIU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vibha111094/OCR/blob/main/OCR_fun.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0N5OxB4gwZf",
        "outputId": "faa3a032-55f6-42a4-9e63-e0c62a290a27"
      },
      "source": [
        "!pip install pytesseract"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading https://files.pythonhosted.org/packages/17/4b/4dbd55388225bb6cd243d21f70e77cb3ce061e241257485936324b8e920f/pytesseract-0.3.6.tar.gz\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from pytesseract) (7.0.0)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.6-py2.py3-none-any.whl size=13629 sha256=289f254c70658b1d5d357ae4626973a69d438faf5a5a0998e8c16852a129c081\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/71/72/b98430261d849ae631e283dfc7ccb456a3fb2ed2205714b63f\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOAKrteQg35E",
        "outputId": "e2c03f84-da34-4a60-c7bb-3129cc92f1e8"
      },
      "source": [
        "!pip install opencv-python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "GZGv4NOPhL8k",
        "outputId": "c65a44b6-cf95-4eaa-87ef-05922d8081d2"
      },
      "source": [
        "!pip install opencv_wrapper"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opencv_wrapper\n",
            "  Downloading https://files.pythonhosted.org/packages/a6/35/07177ec8074623831493c793643b6ec8c444fbc0d7f73a9dfdba486ce65a/opencv-wrapper-0.2.3.tar.gz\n",
            "Collecting numpy<=1.16.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 347kB/s \n",
            "\u001b[?25hCollecting opencv-python<=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/49/874d119948a5a084a7ebe98308214098ef3471d76ab74200f9800efeef15/opencv_python-4.0.0.21-cp36-cp36m-manylinux1_x86_64.whl (25.4MB)\n",
            "\u001b[K     |████████████████████████████████| 25.4MB 1.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from opencv_wrapper) (0.8)\n",
            "Building wheels for collected packages: opencv-wrapper\n",
            "  Building wheel for opencv-wrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for opencv-wrapper: filename=opencv_wrapper-0.2.3-py2.py3-none-any.whl size=18580 sha256=3f9afcec839577bce7922a0e8c94b4348aed4a410e8c3f1fa474b40c64cd1401\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/fc/22/03106b3bcb2516e69317562a2aa4ceb94b0d5813a448edd928\n",
            "Successfully built opencv-wrapper\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.16.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, opencv-python, opencv-wrapper\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "Successfully installed numpy-1.16.2 opencv-python-4.0.0.21 opencv-wrapper-0.2.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgj86v4shbHq",
        "outputId": "94262c5e-1d56-43c0-a792-b3a51c047a36"
      },
      "source": [
        "!pip install colorama"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (0.4.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM2bPdCXg7BT"
      },
      "source": [
        "import pytesseract\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1jpaDXDhCky"
      },
      "source": [
        "# Import PyTorch Library\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Import external libraries\n",
        "import argparse\n",
        "import numpy as np\n",
        "import opencv_wrapper as cvw\n",
        "from skimage.filters import threshold_local\n",
        "import json\n",
        "import random\n",
        "from string import ascii_uppercase, digits, punctuation\n",
        "import colorama\n",
        "import regex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDki8y1RWJjG",
        "outputId": "aba180ac-91a0-43d8-c552-778a1aadd7f0"
      },
      "source": [
        "!which python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/bin/python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yDL0W71WMb7",
        "outputId": "2d2fa3d6-57e3-4c6c-a157-bd3350a0c703"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt7rN4UUXH5f"
      },
      "source": [
        "image = cv2.imread('invoice.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhrVQfizhHHH"
      },
      "source": [
        "def get_info(path):\n",
        "    font     = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    fontScale = 0.5\n",
        "    fontColor  = (255,0,0)\n",
        "    lineType = 1\n",
        "\n",
        "    #Threshold\n",
        "    image = cv2.imread(path)\n",
        "\n",
        "    height,width,channel = image.shape\n",
        "    \n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    T = threshold_local(gray, 15, offset = 6, method = \"gaussian\") # generic, mean, median, gaussian\n",
        "    thresh = (gray > T).astype(\"uint8\") * 255\n",
        "    thresh = ~thresh\n",
        "\n",
        "    #Dilation\n",
        "    kernel =np.ones((1,1), np.uint8)\n",
        "    ero = cv2.erode(thresh, kernel, iterations= 1)\n",
        "    img_dilation = cv2.dilate(ero, kernel, iterations=1)\n",
        "\n",
        "    # Remove noise\n",
        "    nlabels, labels, stats, centroids = cv2.connectedComponentsWithStats(img_dilation, None, None, None, 8, cv2.CV_32S)\n",
        "    sizes = stats[1:, -1] #get CC_STAT_AREA component\n",
        "    final = np.zeros((labels.shape), np.uint8)\n",
        "    for i in range(0, nlabels - 1):\n",
        "        if sizes[i] >= 10:   #filter small dotted regions\n",
        "            final[labels == i + 1] = 255\n",
        "\n",
        "    #Find contours\n",
        "    kern = np.ones((5,15), np.uint8)\n",
        "    img_dilation = cv2.dilate(final, kern, iterations = 1)\n",
        "    contours, hierarchy = cv2.findContours(img_dilation, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
        "    # Map contours to bounding rectangles, using bounding_rect property\n",
        "    rects = map(lambda c: cv2.boundingRect(c), contours)\n",
        "    # Sort rects by top-left x (rect.x == rect.tl.x)\n",
        "    sorted_rects = sorted(rects, key =lambda r: r[0])\n",
        "    sorted_rects = sorted(sorted_rects, key =lambda r: r[1])\n",
        "\n",
        "    etfo=''\n",
        "    for rect in sorted_rects:\n",
        "        x,y,w,h = rect\n",
        "        if(w<20 or h<20):\n",
        "            continue\n",
        "        temp = image[y:y+h, x:x+w]\n",
        "        temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
        "        hi = pytesseract.image_to_data(temp, config=r'--psm 6')\n",
        "        hi = hi.split()\n",
        "        ind = 22\n",
        "        while(True):\n",
        "            if (ind>len(hi)):\n",
        "                break\n",
        "            if(int(hi[ind])==-1):\n",
        "                ind+=11\n",
        "            else:\n",
        "                etfo=etfo+hi[ind+1]\n",
        "                etfo=etfo+\" \"\n",
        "                x+=len(hi[ind+1])*20\n",
        "                ind+=12\n",
        "        etfo=etfo+'\\n'\n",
        "    return etfo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfwomlZjXweH",
        "outputId": "09b6b74b-2dc7-4fe5-c6b0-d259e8986981"
      },
      "source": [
        "!pip install tesseract"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tesseract\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/b7/c4fae9af5842f69d9c45bf1195a94aec090628535c102894552a7a7dbe6c/tesseract-0.1.3.tar.gz (45.6MB)\n",
            "\u001b[K     |████████████████████████████████| 45.6MB 158kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: tesseract\n",
            "  Building wheel for tesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tesseract: filename=tesseract-0.1.3-cp36-none-any.whl size=45562573 sha256=0adeaf87991c0de16770eed71cf6e2c9fed96787fc65a64e924bbb105a54ebae\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/1f/d9/24797b123379e4ea9511cf660835468b62dad609634cad2aba\n",
            "Successfully built tesseract\n",
            "Installing collected packages: tesseract\n",
            "Successfully installed tesseract-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDAf3LoDibrH"
      },
      "source": [
        "class ExtractLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=2, bidirectional=True)\n",
        "        self.linear = nn.Linear(hidden_size * 2, 5)\n",
        "\n",
        "    def forward(self, inpt):\n",
        "        embedded = self.embed(inpt)\n",
        "        feature, _ = self.lstm(embedded)\n",
        "        oupt = self.linear(feature)\n",
        "        return oupt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EguuF4tdYWzq",
        "outputId": "d7a206b3-0cdd-4783-fd8a-bc5591ae89e9"
      },
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install libleptonica-dev \n",
        "!sudo apt-get install tesseract-ocr tesseract-ocr-dev\n",
        "!sudo apt-get install libtesseract-dev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.39)] [Co\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (91.189.91.39)] [Connected to cloud.r-pro\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r                                                                               \rGet:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [3 InRelease 47.5 kB/88.7 kB 54%] [Connecting to security.ubuntu.com (91.189\r0% [3 InRelease 47.5 kB/88.7 kB 54%] [Connecting to security.ubuntu.com (91.189\r0% [2 InRelease gpgv 242 kB] [3 InRelease 47.5 kB/88.7 kB 54%] [Connecting to s\r                                                                               \rGet:5 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "\r0% [2 InRelease gpgv 242 kB] [3 InRelease 47.5 kB/88.7 kB 54%] [Connecting to s\r0% [2 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r0% [2 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rGet:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "\r0% [2 InRelease gpgv 242 kB] [6 InRelease 8,396 B/74.6 kB 11%] [Connecting to s\r0% [2 InRelease gpgv 242 kB] [Connecting to security.ubuntu.com (91.189.91.39)]\r                                                                               \rGet:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,697 kB]\n",
            "Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:13 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [40.7 kB]\n",
            "Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [869 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,136 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [266 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [53.8 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,241 kB]\n",
            "Get:19 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [46.5 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,814 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [15.3 kB]\n",
            "Get:24 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,372 kB]\n",
            "Get:25 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [237 kB]\n",
            "Fetched 11.1 MB in 2s (6,181 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libleptonica-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 36 not upgraded.\n",
            "Need to get 1,308 kB of archives.\n",
            "After this operation, 5,966 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libleptonica-dev amd64 1.75.3-3 [1,308 kB]\n",
            "Fetched 1,308 kB in 0s (12.8 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "(Reading database ... 144865 files and directories currently installed.)\n",
            "Preparing to unpack .../libleptonica-dev_1.75.3-3_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.75.3-3) ...\n",
            "Setting up libleptonica-dev (1.75.3-3) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Package tesseract-ocr-dev is not available, but is referred to by another package.\n",
            "This may mean that the package is missing, has been obsoleted, or\n",
            "is only available from another source\n",
            "However the following packages replace it:\n",
            "  libtesseract-dev\n",
            "\n",
            "E: Package 'tesseract-ocr-dev' has no installation candidate\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libtesseract-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 36 not upgraded.\n",
            "Need to get 1,447 kB of archives.\n",
            "After this operation, 7,824 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libtesseract-dev amd64 4.00~git2288-10f4998a-2 [1,447 kB]\n",
            "Fetched 1,447 kB in 0s (13.6 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libtesseract-dev.\n",
            "(Reading database ... 144908 files and directories currently installed.)\n",
            "Preparing to unpack .../libtesseract-dev_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking libtesseract-dev (4.00~git2288-10f4998a-2) ...\n",
            "Setting up libtesseract-dev (4.00~git2288-10f4998a-2) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vc5iiFM3YjcA",
        "outputId": "cf090ce3-e4c0-4c7e-a421-6a9f31ac3ac2"
      },
      "source": [
        "!pip install tesseract\n",
        "!pip install tesseract-ocr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tesseract\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/b7/c4fae9af5842f69d9c45bf1195a94aec090628535c102894552a7a7dbe6c/tesseract-0.1.3.tar.gz (45.6MB)\n",
            "\u001b[K     |████████████████████████████████| 45.6MB 123kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: tesseract\n",
            "  Building wheel for tesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tesseract: filename=tesseract-0.1.3-cp36-none-any.whl size=45562573 sha256=b29f4857ff02261a276e5543ce444d4a4b1880cb68875e88c5bc320c99cb6d26\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/1f/d9/24797b123379e4ea9511cf660835468b62dad609634cad2aba\n",
            "Successfully built tesseract\n",
            "Installing collected packages: tesseract\n",
            "Successfully installed tesseract-0.1.3\n",
            "Collecting tesseract-ocr\n",
            "  Downloading https://files.pythonhosted.org/packages/e2/0d/dcee3dd0fc4c7bcd18125a98f8ba6d9db7aecaa40770595203e312649587/tesseract-ocr-0.0.1.tar.gz\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from tesseract-ocr) (0.29.21)\n",
            "Building wheels for collected packages: tesseract-ocr\n",
            "  Building wheel for tesseract-ocr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tesseract-ocr: filename=tesseract_ocr-0.0.1-cp36-cp36m-linux_x86_64.whl size=115297 sha256=d5cc8f0eebdc18cd4526755d81704242c70464a575244608f7713ce3f1530d4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/32/ba/e0852fe25fb388c8108871713a344ec638e231d27f53b742db\n",
            "Successfully built tesseract-ocr\n",
            "Installing collected packages: tesseract-ocr\n",
            "Successfully installed tesseract-ocr-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcfRLfhmZKKq",
        "outputId": "806b0a83-950d-4843-a668-7ae1c2eef8b0"
      },
      "source": [
        "!sudo apt-get install tesseract-ocr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 36 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 0s (28.6 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 144976 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwFY8uUAmKCH"
      },
      "source": [
        "etfo = get_info('invoice.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "6B3vc-MGmMjb",
        "outputId": "ac3cc4e5-408c-4d0e-e673-c43db87a0404"
      },
      "source": [
        "etfo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'IPS Shop 27 Plaza ave, Ipsum (000) 23456789012 CASH RECEIPT Adipisc 31.25 Fempor 18.82 Dipsum 2.31 Dreniam 14.30 Vullamco 15.27 Kaboris 4.87 Ecididun 54.50 Magna 75.00 Faliquip 120.50 Total: 459.92 Cash: 370.00 Change: 10.08 THANK YOU FOR SHOPPING \\nIPS Shop 27 Plaza ave, Ipsum (000) 23456789012 CASH RECEIPT Adipisc 31.25 Fempor 18.82 Dipsum 2.31 Dreniam 14.30 Vullamco 15.27 Kaboris 4.87 Ecididun 54.50 Magna 75.00 Faliquip 120.50 Total: 459.92 Cash: 370.00 Change: 10.08 THANK YOU FOR SHOPPING \\nShop \\nIPS \\nPlaza \\nte \\nIpsum \\n(000) \\n23456789012 \\nRECEIPT \\nCASH \\n31.25 \\nAdipisc \\n18.862 \\nFempor \\nDak \\nDipsum \\n14.30 \\nDreniam \\n15.27 \\nVullamco \\n4.87 \\nKaboris \\nEcididun \\n54.50 \\n75.00 \\nMagna \\nFaliquip \\n120.50 \\nTotal: \\n459.92 \\nCash: \\n370.00 \\nChange: \\n10.08 \\nYOU \\nTHANK \\nSHOPPING \\nFOR \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC_4y-GDZalT"
      },
      "source": [
        "def pred_to_dict(text, pred, prob):\n",
        "    res = {\"company\": (\"\", 0), \"date\": (\"\", 0), \"address\": (\"\", 0), \"total\": (\"\", 0)}\n",
        "    keys = list(res.keys())\n",
        "    seps = [0] + (np.nonzero(np.diff(pred))[0] + 1).tolist() + [len(pred)]\n",
        "    for i in range(len(seps) - 1):\n",
        "        pred_class = pred[seps[i]] - 1\n",
        "        if pred_class == -1:\n",
        "            continue\n",
        "\n",
        "        new_key = keys[pred_class]\n",
        "        new_prob = prob[seps[i] : seps[i + 1]].max()\n",
        "        if new_prob > res[new_key][1]:\n",
        "            res[new_key] = (text[seps[i] : seps[i + 1]], new_prob)\n",
        "\n",
        "    return {k: regex.sub(r\"[\\t\\n]\", \" \", v[0].strip()) for k, v in res.items()}\n",
        "\n",
        " \n",
        "def test(model):\n",
        "    model.eval() \n",
        "    with torch.no_grad():\n",
        "            oupt = model(text_tensor)\n",
        "            prob = torch.nn.functional.softmax(oupt, dim=2)\n",
        "            prob, pred = torch.max(prob, dim=2)\n",
        "            prob = prob.squeeze().cpu().numpy()\n",
        "            pred = pred.squeeze().cpu().numpy()\n",
        "            real_text = etfo\n",
        "            result = pred_to_dict(real_text, pred, prob)\n",
        "            with open(\"output.json\", \"w\", encoding=\"utf-8\") as json_opened:\n",
        "                json.dump(result, json_opened, indent=4)\n",
        "            return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzcuHobyksPZ",
        "outputId": "7e93c6c4-50c3-43ff-9d48-d5dccb50521a"
      },
      "source": [
        "VOCAB= ascii_uppercase+digits+punctuation+\" \\t\\n\"\n",
        "\n",
        "#Change to CUDA to run using GPU\n",
        "device = 'cuda'\n",
        "\n",
        "def get_test_data(etfo):  \n",
        "    text = etfo\n",
        "    text_tensor = torch.zeros(len(text), 1, dtype=torch.long)\n",
        "    text_tensor[:, 0] = torch.LongTensor([VOCAB.find(c) for c in text])\n",
        "    return text_tensor.to(device)\n",
        "\n",
        "etfo = get_info('/content/r4.jpeg')\n",
        "# etfo = get_info('X51005621482.jpeg')\n",
        "etfo = etfo.upper()\n",
        "text_tensor = get_test_data(etfo)\n",
        "temp = []\n",
        "for i in range(len(text_tensor)):\n",
        "    if text_tensor[i]>=0 and text_tensor[i]<=70:\n",
        "        temp.append([int(text_tensor[i])])\n",
        "text_tensor = torch.LongTensor(temp)\n",
        "\n",
        "#model initialization\n",
        "hidden_size = 256\n",
        "device= torch.device('cpu')\n",
        "model = ExtractLSTM(len(VOCAB), 16, hidden_size).to(device)\n",
        "model.load_state_dict(torch.load('/content/model.pth'))\n",
        "result = test(model)\n",
        "print(result)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'company': 'TT PEE EE AE', 'date': 'FRI 04/07/', 'address': 'ALAE  EE,  EEE  YW  A  ,.%  AE  —_—  ET  “PE  AE  A  BAR”  EY  A  WE  TUE  SAGE', 'total': ''}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtuGdDbSAlgv"
      },
      "source": [
        "/content/ICDAR-2019-SROIE/task3/src/test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "YlUZAKxm9N8b",
        "outputId": "eed4af01-cad5-46eb-98ff-09aef85a7e6f"
      },
      "source": [
        "etfo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'IPS SHOP 27 PLAZA AVE, IPSUM (000) 23456789012 CASH RECEIPT ADIPISC 31.25 FEMPOR 18.82 DIPSUM 2.31 DRENIAM 14.30 VULLAMCO 15.27 KABORIS 4.87 ECIDIDUN 54.50 MAGNA 75.00 FALIQUIP 120.50 TOTAL: 459.92 CASH: 370.00 CHANGE: 10.08 THANK YOU FOR SHOPPING \\nIPS SHOP 27 PLAZA AVE, IPSUM (000) 23456789012 CASH RECEIPT ADIPISC 31.25 FEMPOR 18.82 DIPSUM 2.31 DRENIAM 14.30 VULLAMCO 15.27 KABORIS 4.87 ECIDIDUN 54.50 MAGNA 75.00 FALIQUIP 120.50 TOTAL: 459.92 CASH: 370.00 CHANGE: 10.08 THANK YOU FOR SHOPPING \\nSHOP \\nIPS \\nPLAZA \\nTE \\nIPSUM \\n(000) \\n23456789012 \\nRECEIPT \\nCASH \\n31.25 \\nADIPISC \\n18.862 \\nFEMPOR \\nDAK \\nDIPSUM \\n14.30 \\nDRENIAM \\n15.27 \\nVULLAMCO \\n4.87 \\nKABORIS \\nECIDIDUN \\n54.50 \\n75.00 \\nMAGNA \\nFALIQUIP \\n120.50 \\nTOTAL: \\n459.92 \\nCASH: \\n370.00 \\nCHANGE: \\n10.08 \\nYOU \\nTHANK \\nSHOPPING \\nFOR \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFZemmD9Z3C3",
        "outputId": "cf9db262-be28-4edc-9953-2e3003017ed3"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ExtractLSTM(\n",
              "  (embed): Embedding(71, 16)\n",
              "  (lstm): LSTM(16, 256, num_layers=2, bidirectional=True)\n",
              "  (linear): Linear(in_features=512, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rd2hDJyZZ50Q",
        "outputId": "833a8dc1-3803-491d-8864-f5f237241e5b"
      },
      "source": [
        "!git clone https://github.com/zzzDavid/ICDAR-2019-SROIE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ICDAR-2019-SROIE'...\n",
            "remote: Enumerating objects: 94, done.\u001b[K\n",
            "remote: Counting objects: 100% (94/94), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 2386 (delta 50), reused 65 (delta 22), pack-reused 2292\u001b[K\n",
            "Receiving objects: 100% (2386/2386), 278.63 MiB | 25.68 MiB/s, done.\n",
            "Resolving deltas: 100% (213/213), done.\n",
            "Checking out files: 100% (1980/1980), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r71bEKV6XA9",
        "outputId": "8a0ed16a-3df5-437c-c5a4-93e8b9269dab"
      },
      "source": [
        "!python /content/ICDAR-2019-SROIE/task3/src/train.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#0001 | Loss: 1.6259\n",
            "#0002 | Loss: 1.5316\n",
            "#0003 | Loss: 1.4297\n",
            "#0004 | Loss: 1.2627\n",
            "#0005 | Loss: 1.2578\n",
            "#0006 | Loss: 1.2494\n",
            "#0007 | Loss: 1.3070\n",
            "#0008 | Loss: 1.2499\n",
            "#0009 | Loss: 1.1691\n",
            "#0010 | Loss: 1.1963\n",
            "#0011 | Loss: 1.1676\n",
            "#0012 | Loss: 1.1626\n",
            "#0013 | Loss: 1.1177\n",
            "#0014 | Loss: 1.1089\n",
            "#0015 | Loss: 1.1304\n",
            "#0016 | Loss: 1.1061\n",
            "#0017 | Loss: 1.0683\n",
            "#0018 | Loss: 1.0492\n",
            "#0019 | Loss: 1.0408\n",
            "#0020 | Loss: 0.9769\n",
            "#0021 | Loss: 0.8429\n",
            "#0022 | Loss: 0.9167\n",
            "#0023 | Loss: 0.9411\n",
            "#0024 | Loss: 0.9112\n",
            "#0025 | Loss: 0.8677\n",
            "#0026 | Loss: 0.8099\n",
            "#0027 | Loss: 0.7039\n",
            "#0028 | Loss: 0.8260\n",
            "#0029 | Loss: 0.9794\n",
            "#0030 | Loss: 0.7049\n",
            "#0031 | Loss: 0.7673\n",
            "#0032 | Loss: 0.5654\n",
            "#0033 | Loss: 0.6884\n",
            "#0034 | Loss: 0.7551\n",
            "#0035 | Loss: 0.6197\n",
            "#0036 | Loss: 0.5376\n",
            "#0037 | Loss: 0.5320\n",
            "#0038 | Loss: 0.5669\n",
            "#0039 | Loss: 0.5402\n",
            "#0040 | Loss: 0.5982\n",
            "#0041 | Loss: 0.5009\n",
            "#0042 | Loss: 0.4410\n",
            "#0043 | Loss: 0.4334\n",
            "#0044 | Loss: 0.4491\n",
            "#0045 | Loss: 0.5517\n",
            "#0046 | Loss: 0.4621\n",
            "#0047 | Loss: 0.4222\n",
            "#0048 | Loss: 0.4614\n",
            "#0049 | Loss: 0.4658\n",
            "#0050 | Loss: 0.4086\n",
            "#0051 | Loss: 0.4159\n",
            "#0052 | Loss: 0.4481\n",
            "#0053 | Loss: 0.3663\n",
            "#0054 | Loss: 0.4363\n",
            "#0055 | Loss: 0.3152\n",
            "#0056 | Loss: 0.3862\n",
            "#0057 | Loss: 0.3580\n",
            "#0058 | Loss: 0.3435\n",
            "#0059 | Loss: 0.3561\n",
            "#0060 | Loss: 0.2968\n",
            "#0061 | Loss: 0.3632\n",
            "#0062 | Loss: 0.6189\n",
            "#0063 | Loss: 0.3247\n",
            "#0064 | Loss: 0.3014\n",
            "#0065 | Loss: 0.2965\n",
            "#0066 | Loss: 0.3669\n",
            "#0067 | Loss: 0.3468\n",
            "#0068 | Loss: 0.2920\n",
            "#0069 | Loss: 0.5036\n",
            "#0070 | Loss: 0.3363\n",
            "#0071 | Loss: 0.3811\n",
            "#0072 | Loss: 0.2209\n",
            "#0073 | Loss: 0.2887\n",
            "#0074 | Loss: 0.2379\n",
            "#0075 | Loss: 0.2116\n",
            "#0076 | Loss: 0.2223\n",
            "#0077 | Loss: 0.2441\n",
            "#0078 | Loss: 0.5766\n",
            "#0079 | Loss: 0.6076\n",
            "#0080 | Loss: 0.3565\n",
            "#0081 | Loss: 0.4222\n",
            "#0082 | Loss: 0.6739\n",
            "#0083 | Loss: 0.5278\n",
            "#0084 | Loss: 0.4043\n",
            "#0085 | Loss: 0.6197\n",
            "#0086 | Loss: 0.3286\n",
            "#0087 | Loss: 0.4303\n",
            "#0088 | Loss: 0.4817\n",
            "#0089 | Loss: 0.3665\n",
            "#0090 | Loss: 0.4217\n",
            "#0091 | Loss: 0.2939\n",
            "#0092 | Loss: 0.3153\n",
            "#0093 | Loss: 0.4042\n",
            "#0094 | Loss: 0.2989\n",
            "#0095 | Loss: 0.2860\n",
            "#0096 | Loss: 0.2603\n",
            "#0097 | Loss: 0.3002\n",
            "#0098 | Loss: 0.2084\n",
            "#0099 | Loss: 0.2262\n",
            "#0100 | Loss: 0.3084\n",
            "#0101 | Loss: 0.2834\n",
            "#0102 | Loss: 0.2337\n",
            "#0103 | Loss: 0.2833\n",
            "#0104 | Loss: 0.2068\n",
            "#0105 | Loss: 0.2419\n",
            "#0106 | Loss: 0.2882\n",
            "#0107 | Loss: 0.2143\n",
            "#0108 | Loss: 0.2185\n",
            "#0109 | Loss: 0.3630\n",
            "#0110 | Loss: 0.2397\n",
            "#0111 | Loss: 0.3141\n",
            "#0112 | Loss: 0.2042\n",
            "#0113 | Loss: 0.1622\n",
            "#0114 | Loss: 0.2611\n",
            "#0115 | Loss: 0.2333\n",
            "#0116 | Loss: 0.2576\n",
            "#0117 | Loss: 0.2146\n",
            "#0118 | Loss: 0.2668\n",
            "#0119 | Loss: 0.2366\n",
            "#0120 | Loss: 0.2391\n",
            "#0121 | Loss: 0.1505\n",
            "#0122 | Loss: 0.1963\n",
            "#0123 | Loss: 0.2681\n",
            "#0124 | Loss: 0.2412\n",
            "#0125 | Loss: 0.2222\n",
            "#0126 | Loss: 0.2182\n",
            "#0127 | Loss: 0.2095\n",
            "#0128 | Loss: 0.2310\n",
            "#0129 | Loss: 0.2390\n",
            "#0130 | Loss: 0.1901\n",
            "#0131 | Loss: 0.1757\n",
            "#0132 | Loss: 0.1759\n",
            "#0133 | Loss: 0.1671\n",
            "#0134 | Loss: 0.1701\n",
            "#0135 | Loss: 0.2154\n",
            "#0136 | Loss: 0.2101\n",
            "#0137 | Loss: 0.1505\n",
            "#0138 | Loss: 0.1654\n",
            "#0139 | Loss: 0.1972\n",
            "#0140 | Loss: 0.2099\n",
            "#0141 | Loss: 0.1591\n",
            "#0142 | Loss: 0.1433\n",
            "#0143 | Loss: 0.2950\n",
            "#0144 | Loss: 0.1424\n",
            "#0145 | Loss: 0.1607\n",
            "#0146 | Loss: 0.1723\n",
            "#0147 | Loss: 0.1792\n",
            "#0148 | Loss: 0.1278\n",
            "#0149 | Loss: 0.1336\n",
            "#0150 | Loss: 0.1969\n",
            "#0151 | Loss: 0.2661\n",
            "#0152 | Loss: 0.1344\n",
            "#0153 | Loss: 0.1561\n",
            "#0154 | Loss: 0.1250\n",
            "#0155 | Loss: 0.1974\n",
            "#0156 | Loss: 0.1835\n",
            "#0157 | Loss: 0.1121\n",
            "#0158 | Loss: 0.1853\n",
            "#0159 | Loss: 0.1468\n",
            "#0160 | Loss: 0.2096\n",
            "#0161 | Loss: 0.1479\n",
            "#0162 | Loss: 0.1386\n",
            "#0163 | Loss: 0.1501\n",
            "#0164 | Loss: 0.1592\n",
            "#0165 | Loss: 0.1823\n",
            "#0166 | Loss: 0.1176\n",
            "#0167 | Loss: 0.1829\n",
            "#0168 | Loss: 0.1221\n",
            "#0169 | Loss: 0.1324\n",
            "#0170 | Loss: 0.1166\n",
            "#0171 | Loss: 0.2135\n",
            "#0172 | Loss: 0.1164\n",
            "#0173 | Loss: 0.1299\n",
            "#0174 | Loss: 0.1260\n",
            "#0175 | Loss: 0.1082\n",
            "#0176 | Loss: 0.1388\n",
            "#0177 | Loss: 0.1531\n",
            "#0178 | Loss: 0.1293\n",
            "#0179 | Loss: 0.1572\n",
            "#0180 | Loss: 0.1980\n",
            "#0181 | Loss: 0.1158\n",
            "#0182 | Loss: 0.1266\n",
            "#0183 | Loss: 0.1221\n",
            "#0184 | Loss: 0.1634\n",
            "#0185 | Loss: 0.1520\n",
            "#0186 | Loss: 0.1323\n",
            "#0187 | Loss: 0.1298\n",
            "#0188 | Loss: 0.1490\n",
            "#0189 | Loss: 0.1514\n",
            "#0190 | Loss: 0.1119\n",
            "#0191 | Loss: 0.1345\n",
            "#0192 | Loss: 0.1264\n",
            "#0193 | Loss: 0.0969\n",
            "#0194 | Loss: 0.1699\n",
            "#0195 | Loss: 0.1141\n",
            "#0196 | Loss: 0.0917\n",
            "#0197 | Loss: 0.2318\n",
            "#0198 | Loss: 0.0884\n",
            "#0199 | Loss: 0.1866\n",
            "#0200 | Loss: 0.1544\n",
            "#0201 | Loss: 0.1538\n",
            "#0202 | Loss: 0.1493\n",
            "#0203 | Loss: 0.1102\n",
            "#0204 | Loss: 0.2428\n",
            "#0205 | Loss: 0.1216\n",
            "#0206 | Loss: 0.1938\n",
            "#0207 | Loss: 0.1003\n",
            "#0208 | Loss: 0.1205\n",
            "#0209 | Loss: 0.1351\n",
            "#0210 | Loss: 0.1433\n",
            "#0211 | Loss: 0.1267\n",
            "#0212 | Loss: 0.1218\n",
            "#0213 | Loss: 0.0906\n",
            "#0214 | Loss: 0.1625\n",
            "#0215 | Loss: 0.1217\n",
            "#0216 | Loss: 0.0989\n",
            "#0217 | Loss: 0.0974\n",
            "#0218 | Loss: 0.1041\n",
            "#0219 | Loss: 0.0793\n",
            "#0220 | Loss: 0.0770\n",
            "#0221 | Loss: 0.1747\n",
            "#0222 | Loss: 0.1460\n",
            "#0223 | Loss: 0.1610\n",
            "#0224 | Loss: 0.0938\n",
            "#0225 | Loss: 0.0914\n",
            "#0226 | Loss: 0.1722\n",
            "#0227 | Loss: 0.1561\n",
            "#0228 | Loss: 0.1104\n",
            "#0229 | Loss: 0.1138\n",
            "#0230 | Loss: 0.1103\n",
            "#0231 | Loss: 0.1104\n",
            "#0232 | Loss: 0.0886\n",
            "#0233 | Loss: 0.1254\n",
            "#0234 | Loss: 0.1278\n",
            "#0235 | Loss: 0.1192\n",
            "#0236 | Loss: 0.0944\n",
            "#0237 | Loss: 0.1448\n",
            "#0238 | Loss: 0.1060\n",
            "#0239 | Loss: 0.1188\n",
            "#0240 | Loss: 0.0983\n",
            "#0241 | Loss: 0.1347\n",
            "#0242 | Loss: 0.0949\n",
            "#0243 | Loss: 0.1270\n",
            "#0244 | Loss: 0.1003\n",
            "#0245 | Loss: 0.0872\n",
            "#0246 | Loss: 0.1068\n",
            "#0247 | Loss: 0.0748\n",
            "#0248 | Loss: 0.1084\n",
            "#0249 | Loss: 0.0950\n",
            "#0250 | Loss: 0.1609\n",
            "#0251 | Loss: 0.1411\n",
            "#0252 | Loss: 0.1111\n",
            "#0253 | Loss: 0.0655\n",
            "#0254 | Loss: 0.0909\n",
            "#0255 | Loss: 0.0831\n",
            "#0256 | Loss: 0.0976\n",
            "#0257 | Loss: 0.0785\n",
            "#0258 | Loss: 0.0899\n",
            "#0259 | Loss: 0.1227\n",
            "#0260 | Loss: 0.1229\n",
            "#0261 | Loss: 0.0930\n",
            "#0262 | Loss: 0.1055\n",
            "#0263 | Loss: 0.2380\n",
            "#0264 | Loss: 0.0658\n",
            "#0265 | Loss: 0.1330\n",
            "#0266 | Loss: 0.1213\n",
            "#0267 | Loss: 0.1512\n",
            "#0268 | Loss: 0.1454\n",
            "#0269 | Loss: 0.1142\n",
            "#0270 | Loss: 0.0792\n",
            "#0271 | Loss: 0.1066\n",
            "#0272 | Loss: 0.1042\n",
            "#0273 | Loss: 0.0836\n",
            "#0274 | Loss: 0.1514\n",
            "#0275 | Loss: 0.1461\n",
            "#0276 | Loss: 0.0986\n",
            "#0277 | Loss: 0.1292\n",
            "#0278 | Loss: 0.1017\n",
            "#0279 | Loss: 0.0828\n",
            "#0280 | Loss: 0.1211\n",
            "#0281 | Loss: 0.1130\n",
            "#0282 | Loss: 0.1030\n",
            "#0283 | Loss: 0.0915\n",
            "#0284 | Loss: 0.1316\n",
            "#0285 | Loss: 0.1471\n",
            "#0286 | Loss: 0.0801\n",
            "#0287 | Loss: 0.0983\n",
            "#0288 | Loss: 0.1082\n",
            "#0289 | Loss: 0.0924\n",
            "#0290 | Loss: 0.0927\n",
            "#0291 | Loss: 0.1021\n",
            "#0292 | Loss: 0.0926\n",
            "#0293 | Loss: 0.0705\n",
            "#0294 | Loss: 0.1027\n",
            "#0295 | Loss: 0.0786\n",
            "#0296 | Loss: 0.0648\n",
            "#0297 | Loss: 0.1184\n",
            "#0298 | Loss: 0.0513\n",
            "#0299 | Loss: 0.0850\n",
            "#0300 | Loss: 0.0717\n",
            "#0301 | Loss: 0.1977\n",
            "#0302 | Loss: 0.5701\n",
            "#0303 | Loss: 0.8478\n",
            "#0304 | Loss: 1.5622\n",
            "#0305 | Loss: 0.3942\n",
            "#0306 | Loss: 0.5425\n",
            "#0307 | Loss: 0.7357\n",
            "#0308 | Loss: 0.5353\n",
            "#0309 | Loss: 0.3196\n",
            "#0310 | Loss: 0.5122\n",
            "#0311 | Loss: 0.4810\n",
            "#0312 | Loss: 0.4236\n",
            "#0313 | Loss: 0.3468\n",
            "#0314 | Loss: 0.3422\n",
            "#0315 | Loss: 0.3090\n",
            "#0316 | Loss: 0.3132\n",
            "#0317 | Loss: 0.2437\n",
            "#0318 | Loss: 0.2420\n",
            "#0319 | Loss: 0.2304\n",
            "#0320 | Loss: 0.3466\n",
            "#0321 | Loss: 0.1844\n",
            "#0322 | Loss: 0.2027\n",
            "#0323 | Loss: 0.3545\n",
            "#0324 | Loss: 0.1885\n",
            "#0325 | Loss: 0.2117\n",
            "#0326 | Loss: 0.2825\n",
            "#0327 | Loss: 0.2014\n",
            "#0328 | Loss: 0.2129\n",
            "#0329 | Loss: 0.2057\n",
            "#0330 | Loss: 0.1754\n",
            "#0331 | Loss: 0.2343\n",
            "#0332 | Loss: 0.1746\n",
            "#0333 | Loss: 0.1696\n",
            "#0334 | Loss: 0.2657\n",
            "#0335 | Loss: 0.1738\n",
            "#0336 | Loss: 0.1904\n",
            "#0337 | Loss: 0.1939\n",
            "#0338 | Loss: 0.1306\n",
            "#0339 | Loss: 0.1061\n",
            "#0340 | Loss: 0.2427\n",
            "#0341 | Loss: 0.1494\n",
            "#0342 | Loss: 0.1725\n",
            "#0343 | Loss: 0.1313\n",
            "#0344 | Loss: 0.1089\n",
            "#0345 | Loss: 0.1353\n",
            "#0346 | Loss: 0.1435\n",
            "#0347 | Loss: 0.2918\n",
            "#0348 | Loss: 0.1220\n",
            "#0349 | Loss: 0.1648\n",
            "#0350 | Loss: 0.1668\n",
            "#0351 | Loss: 0.0971\n",
            "#0352 | Loss: 0.1529\n",
            "#0353 | Loss: 0.2245\n",
            "#0354 | Loss: 0.1673\n",
            "#0355 | Loss: 0.1315\n",
            "#0356 | Loss: 0.2567\n",
            "#0357 | Loss: 0.0965\n",
            "#0358 | Loss: 0.1757\n",
            "#0359 | Loss: 0.1833\n",
            "#0360 | Loss: 0.1655\n",
            "#0361 | Loss: 0.1984\n",
            "#0362 | Loss: 0.1360\n",
            "#0363 | Loss: 0.1981\n",
            "#0364 | Loss: 0.1101\n",
            "#0365 | Loss: 0.1321\n",
            "#0366 | Loss: 0.1237\n",
            "#0367 | Loss: 0.1012\n",
            "#0368 | Loss: 0.1744\n",
            "#0369 | Loss: 0.1165\n",
            "#0370 | Loss: 0.1673\n",
            "#0371 | Loss: 0.1773\n",
            "#0372 | Loss: 0.1096\n",
            "#0373 | Loss: 0.0986\n",
            "#0374 | Loss: 0.1689\n",
            "#0375 | Loss: 0.1073\n",
            "#0376 | Loss: 0.1104\n",
            "#0377 | Loss: 0.1264\n",
            "#0378 | Loss: 0.0695\n",
            "#0379 | Loss: 0.0918\n",
            "#0380 | Loss: 0.0827\n",
            "#0381 | Loss: 0.1030\n",
            "#0382 | Loss: 0.1041\n",
            "#0383 | Loss: 0.1145\n",
            "#0384 | Loss: 0.1298\n",
            "#0385 | Loss: 0.1197\n",
            "#0386 | Loss: 0.0954\n",
            "#0387 | Loss: 0.1099\n",
            "#0388 | Loss: 0.1056\n",
            "#0389 | Loss: 0.0777\n",
            "#0390 | Loss: 0.1099\n",
            "#0391 | Loss: 0.1453\n",
            "#0392 | Loss: 0.1151\n",
            "#0393 | Loss: 0.0818\n",
            "#0394 | Loss: 0.0830\n",
            "#0395 | Loss: 0.0896\n",
            "#0396 | Loss: 0.0800\n",
            "#0397 | Loss: 0.0959\n",
            "#0398 | Loss: 0.1595\n",
            "#0399 | Loss: 0.1162\n",
            "#0400 | Loss: 0.0962\n",
            "#0401 | Loss: 0.1047\n",
            "#0402 | Loss: 0.1131\n",
            "#0403 | Loss: 0.1091\n",
            "#0404 | Loss: 0.0695\n",
            "#0405 | Loss: 0.1010\n",
            "#0406 | Loss: 0.0739\n",
            "#0407 | Loss: 0.0792\n",
            "#0408 | Loss: 0.0866\n",
            "#0409 | Loss: 0.1413\n",
            "#0410 | Loss: 0.1031\n",
            "#0411 | Loss: 0.1105\n",
            "#0412 | Loss: 0.0779\n",
            "#0413 | Loss: 0.0884\n",
            "#0414 | Loss: 0.0772\n",
            "#0415 | Loss: 0.1120\n",
            "#0416 | Loss: 0.1606\n",
            "#0417 | Loss: 0.0800\n",
            "#0418 | Loss: 0.0871\n",
            "#0419 | Loss: 0.0761\n",
            "#0420 | Loss: 0.0835\n",
            "#0421 | Loss: 0.0797\n",
            "#0422 | Loss: 0.1018\n",
            "#0423 | Loss: 0.0981\n",
            "#0424 | Loss: 0.0798\n",
            "#0425 | Loss: 0.0907\n",
            "#0426 | Loss: 0.1126\n",
            "#0427 | Loss: 0.0754\n",
            "#0428 | Loss: 0.0690\n",
            "#0429 | Loss: 0.0750\n",
            "#0430 | Loss: 0.1043\n",
            "#0431 | Loss: 0.1245\n",
            "#0432 | Loss: 0.0588\n",
            "#0433 | Loss: 0.0773\n",
            "#0434 | Loss: 0.1069\n",
            "#0435 | Loss: 0.0811\n",
            "#0436 | Loss: 0.0790\n",
            "#0437 | Loss: 0.0815\n",
            "#0438 | Loss: 0.1340\n",
            "#0439 | Loss: 0.0598\n",
            "#0440 | Loss: 0.0756\n",
            "#0441 | Loss: 0.0941\n",
            "#0442 | Loss: 0.0793\n",
            "#0443 | Loss: 0.0769\n",
            "#0444 | Loss: 0.1210\n",
            "#0445 | Loss: 0.1368\n",
            "#0446 | Loss: 0.0682\n",
            "#0447 | Loss: 0.0453\n",
            "#0448 | Loss: 0.0820\n",
            "#0449 | Loss: 0.0860\n",
            "#0450 | Loss: 0.0728\n",
            "#0451 | Loss: 0.0995\n",
            "#0452 | Loss: 0.0544\n",
            "#0453 | Loss: 0.1017\n",
            "#0454 | Loss: 0.0460\n",
            "#0455 | Loss: 0.0785\n",
            "#0456 | Loss: 0.0747\n",
            "#0457 | Loss: 0.0636\n",
            "#0458 | Loss: 0.0633\n",
            "#0459 | Loss: 0.0539\n",
            "#0460 | Loss: 0.1018\n",
            "#0461 | Loss: 0.0898\n",
            "#0462 | Loss: 0.0620\n",
            "#0463 | Loss: 0.0763\n",
            "#0464 | Loss: 0.0841\n",
            "#0465 | Loss: 0.0731\n",
            "#0466 | Loss: 0.0708\n",
            "#0467 | Loss: 0.1201\n",
            "#0468 | Loss: 0.0568\n",
            "#0469 | Loss: 0.0639\n",
            "#0470 | Loss: 0.1018\n",
            "#0471 | Loss: 0.0884\n",
            "#0472 | Loss: 0.0586\n",
            "#0473 | Loss: 0.0503\n",
            "#0474 | Loss: 0.0738\n",
            "#0475 | Loss: 0.0751\n",
            "#0476 | Loss: 0.1020\n",
            "#0477 | Loss: 0.0552\n",
            "#0478 | Loss: 0.0619\n",
            "#0479 | Loss: 0.1071\n",
            "#0480 | Loss: 0.0561\n",
            "#0481 | Loss: 0.0914\n",
            "#0482 | Loss: 0.0914\n",
            "#0483 | Loss: 0.0599\n",
            "#0484 | Loss: 0.0565\n",
            "#0485 | Loss: 0.0555\n",
            "#0486 | Loss: 0.0755\n",
            "#0487 | Loss: 0.1370\n",
            "#0488 | Loss: 0.0762\n",
            "#0489 | Loss: 0.0559\n",
            "#0490 | Loss: 0.1068\n",
            "#0491 | Loss: 0.0478\n",
            "#0492 | Loss: 0.0631\n",
            "#0493 | Loss: 0.0598\n",
            "#0494 | Loss: 0.0678\n",
            "#0495 | Loss: 0.0691\n",
            "#0496 | Loss: 0.0974\n",
            "#0497 | Loss: 0.0620\n",
            "#0498 | Loss: 0.0816\n",
            "#0499 | Loss: 0.0574\n",
            "#0500 | Loss: 0.0542\n",
            "#0501 | Loss: 0.0550\n",
            "#0502 | Loss: 0.0604\n",
            "#0503 | Loss: 0.1082\n",
            "#0504 | Loss: 0.0890\n",
            "#0505 | Loss: 0.0662\n",
            "#0506 | Loss: 0.0905\n",
            "#0507 | Loss: 0.0531\n",
            "#0508 | Loss: 0.0768\n",
            "#0509 | Loss: 0.0801\n",
            "#0510 | Loss: 0.1103\n",
            "#0511 | Loss: 0.0404\n",
            "#0512 | Loss: 0.0465\n",
            "#0513 | Loss: 0.0521\n",
            "#0514 | Loss: 0.0622\n",
            "#0515 | Loss: 0.0794\n",
            "#0516 | Loss: 0.0546\n",
            "#0517 | Loss: 0.0618\n",
            "#0518 | Loss: 0.0705\n",
            "#0519 | Loss: 0.0857\n",
            "#0520 | Loss: 0.1212\n",
            "#0521 | Loss: 0.0940\n",
            "#0522 | Loss: 0.0678\n",
            "#0523 | Loss: 0.0610\n",
            "#0524 | Loss: 0.0579\n",
            "#0525 | Loss: 0.0467\n",
            "#0526 | Loss: 0.1080\n",
            "#0527 | Loss: 0.0540\n",
            "#0528 | Loss: 0.0328\n",
            "#0529 | Loss: 0.0511\n",
            "#0530 | Loss: 0.0781\n",
            "#0531 | Loss: 0.0630\n",
            "#0532 | Loss: 0.0499\n",
            "#0533 | Loss: 0.0653\n",
            "#0534 | Loss: 0.0726\n",
            "#0535 | Loss: 0.0432\n",
            "#0536 | Loss: 0.0463\n",
            "#0537 | Loss: 0.0466\n",
            "#0538 | Loss: 0.0412\n",
            "#0539 | Loss: 0.0624\n",
            "#0540 | Loss: 0.0737\n",
            "#0541 | Loss: 0.0536\n",
            "#0542 | Loss: 0.0638\n",
            "#0543 | Loss: 0.0930\n",
            "#0544 | Loss: 0.0615\n",
            "#0545 | Loss: 0.0843\n",
            "#0546 | Loss: 0.0702\n",
            "#0547 | Loss: 0.0610\n",
            "#0548 | Loss: 0.0696\n",
            "#0549 | Loss: 0.0699\n",
            "#0550 | Loss: 0.0791\n",
            "#0551 | Loss: 0.0542\n",
            "#0552 | Loss: 0.0549\n",
            "#0553 | Loss: 0.0851\n",
            "#0554 | Loss: 0.0625\n",
            "#0555 | Loss: 0.0578\n",
            "#0556 | Loss: 0.0690\n",
            "#0557 | Loss: 0.1116\n",
            "#0558 | Loss: 0.0337\n",
            "#0559 | Loss: 0.0469\n",
            "#0560 | Loss: 0.0528\n",
            "#0561 | Loss: 0.0409\n",
            "#0562 | Loss: 0.0405\n",
            "#0563 | Loss: 0.0530\n",
            "#0564 | Loss: 0.0423\n",
            "#0565 | Loss: 0.0484\n",
            "#0566 | Loss: 0.0639\n",
            "#0567 | Loss: 0.0503\n",
            "#0568 | Loss: 0.0542\n",
            "#0569 | Loss: 0.0739\n",
            "#0570 | Loss: 0.0572\n",
            "#0571 | Loss: 0.0470\n",
            "#0572 | Loss: 0.0825\n",
            "#0573 | Loss: 0.0434\n",
            "#0574 | Loss: 0.0526\n",
            "#0575 | Loss: 0.0475\n",
            "#0576 | Loss: 0.0364\n",
            "#0577 | Loss: 0.0652\n",
            "#0578 | Loss: 0.0362\n",
            "#0579 | Loss: 0.0457\n",
            "#0580 | Loss: 0.0524\n",
            "#0581 | Loss: 0.0525\n",
            "#0582 | Loss: 0.0756\n",
            "#0583 | Loss: 0.0429\n",
            "#0584 | Loss: 0.0906\n",
            "#0585 | Loss: 0.0368\n",
            "#0586 | Loss: 0.0469\n",
            "#0587 | Loss: 0.0676\n",
            "#0588 | Loss: 0.1040\n",
            "#0589 | Loss: 0.0378\n",
            "#0590 | Loss: 0.0625\n",
            "#0591 | Loss: 0.0543\n",
            "#0592 | Loss: 0.0541\n",
            "#0593 | Loss: 0.0837\n",
            "#0594 | Loss: 0.0401\n",
            "#0595 | Loss: 0.0529\n",
            "#0596 | Loss: 0.0560\n",
            "#0597 | Loss: 0.0375\n",
            "#0598 | Loss: 0.0572\n",
            "#0599 | Loss: 0.0838\n",
            "#0600 | Loss: 0.0286\n",
            "#0601 | Loss: 0.0365\n",
            "#0602 | Loss: 0.0581\n",
            "#0603 | Loss: 0.0902\n",
            "#0604 | Loss: 0.0672\n",
            "#0605 | Loss: 0.0433\n",
            "#0606 | Loss: 0.0752\n",
            "#0607 | Loss: 0.0557\n",
            "#0608 | Loss: 0.0465\n",
            "#0609 | Loss: 0.0527\n",
            "#0610 | Loss: 0.0463\n",
            "#0611 | Loss: 0.0938\n",
            "#0612 | Loss: 0.0554\n",
            "#0613 | Loss: 0.0544\n",
            "#0614 | Loss: 0.0422\n",
            "#0615 | Loss: 0.0392\n",
            "#0616 | Loss: 0.0742\n",
            "#0617 | Loss: 0.0422\n",
            "#0618 | Loss: 0.0426\n",
            "#0619 | Loss: 0.0481\n",
            "#0620 | Loss: 0.0560\n",
            "#0621 | Loss: 0.0366\n",
            "#0622 | Loss: 0.0480\n",
            "#0623 | Loss: 0.0530\n",
            "#0624 | Loss: 0.0457\n",
            "#0625 | Loss: 0.0835\n",
            "#0626 | Loss: 0.0720\n",
            "#0627 | Loss: 0.0523\n",
            "#0628 | Loss: 0.0527\n",
            "#0629 | Loss: 0.0490\n",
            "#0630 | Loss: 0.0452\n",
            "#0631 | Loss: 0.0978\n",
            "#0632 | Loss: 0.0934\n",
            "#0633 | Loss: 0.0722\n",
            "#0634 | Loss: 0.0385\n",
            "#0635 | Loss: 0.0865\n",
            "#0636 | Loss: 0.0468\n",
            "#0637 | Loss: 0.0727\n",
            "#0638 | Loss: 0.0402\n",
            "#0639 | Loss: 0.0552\n",
            "#0640 | Loss: 0.0663\n",
            "#0641 | Loss: 0.0471\n",
            "#0642 | Loss: 0.0426\n",
            "#0643 | Loss: 0.0684\n",
            "#0644 | Loss: 0.0388\n",
            "#0645 | Loss: 0.0604\n",
            "#0646 | Loss: 0.0385\n",
            "#0647 | Loss: 0.0480\n",
            "#0648 | Loss: 0.0321\n",
            "#0649 | Loss: 0.0546\n",
            "#0650 | Loss: 0.0798\n",
            "#0651 | Loss: 0.0588\n",
            "#0652 | Loss: 0.0309\n",
            "#0653 | Loss: 0.0427\n",
            "#0654 | Loss: 0.0321\n",
            "#0655 | Loss: 0.0301\n",
            "#0656 | Loss: 0.0522\n",
            "#0657 | Loss: 0.0587\n",
            "#0658 | Loss: 0.0618\n",
            "#0659 | Loss: 0.0600\n",
            "#0660 | Loss: 0.0555\n",
            "#0661 | Loss: 0.0972\n",
            "#0662 | Loss: 0.0398\n",
            "#0663 | Loss: 0.0624\n",
            "#0664 | Loss: 0.0502\n",
            "#0665 | Loss: 0.0529\n",
            "#0666 | Loss: 0.0412\n",
            "#0667 | Loss: 0.0625\n",
            "#0668 | Loss: 0.0373\n",
            "#0669 | Loss: 0.0339\n",
            "#0670 | Loss: 0.0694\n",
            "#0671 | Loss: 0.0383\n",
            "#0672 | Loss: 0.0406\n",
            "#0673 | Loss: 0.0474\n",
            "#0674 | Loss: 0.0463\n",
            "#0675 | Loss: 0.0314\n",
            "#0676 | Loss: 0.0462\n",
            "#0677 | Loss: 0.0341\n",
            "#0678 | Loss: 0.0597\n",
            "#0679 | Loss: 0.0513\n",
            "#0680 | Loss: 0.0338\n",
            "#0681 | Loss: 0.0678\n",
            "#0682 | Loss: 0.0691\n",
            "#0683 | Loss: 0.0527\n",
            "#0684 | Loss: 0.0373\n",
            "#0685 | Loss: 0.0518\n",
            "#0686 | Loss: 0.0504\n",
            "#0687 | Loss: 0.0447\n",
            "#0688 | Loss: 0.0414\n",
            "#0689 | Loss: 0.0334\n",
            "#0690 | Loss: 0.0466\n",
            "#0691 | Loss: 0.0567\n",
            "#0692 | Loss: 0.0430\n",
            "#0693 | Loss: 0.0459\n",
            "#0694 | Loss: 0.0538\n",
            "#0695 | Loss: 0.0457\n",
            "#0696 | Loss: 0.0519\n",
            "#0697 | Loss: 0.0331\n",
            "#0698 | Loss: 0.0410\n",
            "#0699 | Loss: 0.0470\n",
            "#0700 | Loss: 0.0370\n",
            "#0701 | Loss: 0.0606\n",
            "#0702 | Loss: 0.0573\n",
            "#0703 | Loss: 0.0402\n",
            "#0704 | Loss: 0.0416\n",
            "#0705 | Loss: 0.0402\n",
            "#0706 | Loss: 0.0426\n",
            "#0707 | Loss: 0.0344\n",
            "#0708 | Loss: 0.0369\n",
            "#0709 | Loss: 0.0469\n",
            "#0710 | Loss: 0.0472\n",
            "#0711 | Loss: 0.0373\n",
            "#0712 | Loss: 0.0252\n",
            "#0713 | Loss: 0.0425\n",
            "#0714 | Loss: 0.0311\n",
            "#0715 | Loss: 0.0468\n",
            "#0716 | Loss: 0.0418\n",
            "#0717 | Loss: 0.0360\n",
            "#0718 | Loss: 0.0522\n",
            "#0719 | Loss: 0.0419\n",
            "#0720 | Loss: 0.0465\n",
            "#0721 | Loss: 0.0500\n",
            "#0722 | Loss: 0.0600\n",
            "#0723 | Loss: 0.0403\n",
            "#0724 | Loss: 0.0332\n",
            "#0725 | Loss: 0.0442\n",
            "#0726 | Loss: 0.0366\n",
            "#0727 | Loss: 0.0556\n",
            "#0728 | Loss: 0.0379\n",
            "#0729 | Loss: 0.0356\n",
            "#0730 | Loss: 0.0560\n",
            "#0731 | Loss: 0.0400\n",
            "#0732 | Loss: 0.0668\n",
            "#0733 | Loss: 0.0601\n",
            "#0734 | Loss: 0.0370\n",
            "#0735 | Loss: 0.0417\n",
            "#0736 | Loss: 0.0334\n",
            "#0737 | Loss: 0.0328\n",
            "#0738 | Loss: 0.0438\n",
            "#0739 | Loss: 0.0344\n",
            "#0740 | Loss: 0.0429\n",
            "#0741 | Loss: 0.0311\n",
            "#0742 | Loss: 0.0384\n",
            "#0743 | Loss: 0.0221\n",
            "#0744 | Loss: 0.0391\n",
            "#0745 | Loss: 0.0200\n",
            "#0746 | Loss: 0.0691\n",
            "#0747 | Loss: 0.0322\n",
            "#0748 | Loss: 0.0394\n",
            "#0749 | Loss: 0.0359\n",
            "#0750 | Loss: 0.0407\n",
            "#0751 | Loss: 0.0407\n",
            "#0752 | Loss: 0.0295\n",
            "#0753 | Loss: 0.0248\n",
            "#0754 | Loss: 0.0366\n",
            "#0755 | Loss: 0.0353\n",
            "#0756 | Loss: 0.0509\n",
            "#0757 | Loss: 0.0457\n",
            "#0758 | Loss: 0.0353\n",
            "#0759 | Loss: 0.0384\n",
            "#0760 | Loss: 0.0708\n",
            "#0761 | Loss: 0.0659\n",
            "#0762 | Loss: 0.0455\n",
            "#0763 | Loss: 0.0319\n",
            "#0764 | Loss: 0.0314\n",
            "#0765 | Loss: 0.0433\n",
            "#0766 | Loss: 0.0713\n",
            "#0767 | Loss: 0.0483\n",
            "#0768 | Loss: 0.0436\n",
            "#0769 | Loss: 0.0559\n",
            "#0770 | Loss: 0.0331\n",
            "#0771 | Loss: 0.0458\n",
            "#0772 | Loss: 0.0391\n",
            "#0773 | Loss: 0.0348\n",
            "#0774 | Loss: 0.0542\n",
            "#0775 | Loss: 0.0367\n",
            "#0776 | Loss: 0.0368\n",
            "#0777 | Loss: 0.0439\n",
            "#0778 | Loss: 0.0407\n",
            "#0779 | Loss: 0.0666\n",
            "#0780 | Loss: 0.0553\n",
            "#0781 | Loss: 0.0605\n",
            "#0782 | Loss: 0.0598\n",
            "#0783 | Loss: 0.0446\n",
            "#0784 | Loss: 0.0399\n",
            "#0785 | Loss: 0.0777\n",
            "#0786 | Loss: 0.0243\n",
            "#0787 | Loss: 0.0384\n",
            "#0788 | Loss: 0.0389\n",
            "#0789 | Loss: 0.0312\n",
            "#0790 | Loss: 0.0700\n",
            "#0791 | Loss: 0.0380\n",
            "#0792 | Loss: 0.0370\n",
            "#0793 | Loss: 0.0490\n",
            "#0794 | Loss: 0.0173\n",
            "#0795 | Loss: 0.0291\n",
            "#0796 | Loss: 0.0236\n",
            "#0797 | Loss: 0.0482\n",
            "#0798 | Loss: 0.0273\n",
            "#0799 | Loss: 0.0411\n",
            "#0800 | Loss: 0.0364\n",
            "#0801 | Loss: 0.0229\n",
            "#0802 | Loss: 0.0261\n",
            "#0803 | Loss: 0.0241\n",
            "#0804 | Loss: 0.0490\n",
            "#0805 | Loss: 0.0358\n",
            "#0806 | Loss: 0.0304\n",
            "#0807 | Loss: 0.0441\n",
            "#0808 | Loss: 0.0349\n",
            "#0809 | Loss: 0.0304\n",
            "#0810 | Loss: 0.0343\n",
            "#0811 | Loss: 0.0676\n",
            "#0812 | Loss: 0.0231\n",
            "#0813 | Loss: 0.0629\n",
            "#0814 | Loss: 0.0437\n",
            "#0815 | Loss: 0.0737\n",
            "#0816 | Loss: 0.0545\n",
            "#0817 | Loss: 0.0453\n",
            "#0818 | Loss: 0.0666\n",
            "#0819 | Loss: 0.0706\n",
            "#0820 | Loss: 0.0577\n",
            "#0821 | Loss: 0.0392\n",
            "#0822 | Loss: 0.0433\n",
            "#0823 | Loss: 0.0540\n",
            "#0824 | Loss: 0.0534\n",
            "#0825 | Loss: 0.0480\n",
            "#0826 | Loss: 0.0431\n",
            "#0827 | Loss: 0.0462\n",
            "#0828 | Loss: 0.0570\n",
            "#0829 | Loss: 0.0436\n",
            "#0830 | Loss: 0.0384\n",
            "#0831 | Loss: 0.0359\n",
            "#0832 | Loss: 0.0306\n",
            "#0833 | Loss: 0.0568\n",
            "#0834 | Loss: 0.0425\n",
            "#0835 | Loss: 0.0548\n",
            "#0836 | Loss: 0.0827\n",
            "#0837 | Loss: 0.0369\n",
            "#0838 | Loss: 0.0297\n",
            "#0839 | Loss: 0.0331\n",
            "#0840 | Loss: 0.0347\n",
            "#0841 | Loss: 0.0283\n",
            "#0842 | Loss: 0.0381\n",
            "#0843 | Loss: 0.0281\n",
            "#0844 | Loss: 0.0390\n",
            "#0845 | Loss: 0.0501\n",
            "#0846 | Loss: 0.0448\n",
            "#0847 | Loss: 0.0285\n",
            "#0848 | Loss: 0.0360\n",
            "#0849 | Loss: 0.0403\n",
            "#0850 | Loss: 0.0363\n",
            "#0851 | Loss: 0.0302\n",
            "#0852 | Loss: 0.0565\n",
            "#0853 | Loss: 0.0483\n",
            "#0854 | Loss: 0.0306\n",
            "#0855 | Loss: 0.0503\n",
            "#0856 | Loss: 0.0408\n",
            "#0857 | Loss: 0.0649\n",
            "#0858 | Loss: 0.0238\n",
            "#0859 | Loss: 0.0400\n",
            "#0860 | Loss: 0.0402\n",
            "#0861 | Loss: 0.0252\n",
            "#0862 | Loss: 0.0318\n",
            "#0863 | Loss: 0.0305\n",
            "#0864 | Loss: 0.0351\n",
            "#0865 | Loss: 0.0453\n",
            "#0866 | Loss: 0.0403\n",
            "#0867 | Loss: 0.0397\n",
            "#0868 | Loss: 0.0432\n",
            "#0869 | Loss: 0.0363\n",
            "#0870 | Loss: 0.0223\n",
            "#0871 | Loss: 0.0327\n",
            "#0872 | Loss: 0.0359\n",
            "#0873 | Loss: 0.0212\n",
            "#0874 | Loss: 0.0288\n",
            "#0875 | Loss: 0.0257\n",
            "#0876 | Loss: 0.0256\n",
            "#0877 | Loss: 0.0315\n",
            "#0878 | Loss: 0.0215\n",
            "#0879 | Loss: 0.0257\n",
            "#0880 | Loss: 0.0334\n",
            "#0881 | Loss: 0.0385\n",
            "#0882 | Loss: 0.0324\n",
            "#0883 | Loss: 0.0750\n",
            "#0884 | Loss: 0.0207\n",
            "#0885 | Loss: 0.0279\n",
            "#0886 | Loss: 0.0255\n",
            "#0887 | Loss: 0.0887\n",
            "#0888 | Loss: 0.0390\n",
            "#0889 | Loss: 0.0491\n",
            "#0890 | Loss: 0.0387\n",
            "#0891 | Loss: 0.0303\n",
            "#0892 | Loss: 0.0599\n",
            "#0893 | Loss: 0.0363\n",
            "#0894 | Loss: 0.0388\n",
            "#0895 | Loss: 0.0343\n",
            "#0896 | Loss: 0.0280\n",
            "#0897 | Loss: 0.0389\n",
            "#0898 | Loss: 0.0329\n",
            "#0899 | Loss: 0.0273\n",
            "#0900 | Loss: 0.0471\n",
            "#0901 | Loss: 0.0367\n",
            "#0902 | Loss: 0.0397\n",
            "#0903 | Loss: 0.0231\n",
            "#0904 | Loss: 0.0284\n",
            "#0905 | Loss: 0.0219\n",
            "#0906 | Loss: 0.0293\n",
            "#0907 | Loss: 0.0194\n",
            "#0908 | Loss: 0.0285\n",
            "#0909 | Loss: 0.0227\n",
            "#0910 | Loss: 0.0420\n",
            "#0911 | Loss: 0.0474\n",
            "#0912 | Loss: 0.0547\n",
            "#0913 | Loss: 0.0476\n",
            "#0914 | Loss: 0.0260\n",
            "#0915 | Loss: 0.0207\n",
            "#0916 | Loss: 0.0383\n",
            "#0917 | Loss: 0.0274\n",
            "#0918 | Loss: 0.0322\n",
            "#0919 | Loss: 0.0242\n",
            "#0920 | Loss: 0.0454\n",
            "#0921 | Loss: 0.0382\n",
            "#0922 | Loss: 0.0240\n",
            "#0923 | Loss: 0.0263\n",
            "#0924 | Loss: 0.0214\n",
            "#0925 | Loss: 0.0281\n",
            "#0926 | Loss: 0.0187\n",
            "#0927 | Loss: 0.0232\n",
            "#0928 | Loss: 0.0318\n",
            "#0929 | Loss: 0.0383\n",
            "#0930 | Loss: 0.0270\n",
            "#0931 | Loss: 0.0198\n",
            "#0932 | Loss: 0.0441\n",
            "#0933 | Loss: 0.0225\n",
            "#0934 | Loss: 0.0343\n",
            "#0935 | Loss: 0.0242\n",
            "#0936 | Loss: 0.0355\n",
            "#0937 | Loss: 0.0339\n",
            "#0938 | Loss: 0.0264\n",
            "#0939 | Loss: 0.0351\n",
            "#0940 | Loss: 0.0226\n",
            "#0941 | Loss: 0.0252\n",
            "#0942 | Loss: 0.0187\n",
            "#0943 | Loss: 0.0444\n",
            "#0944 | Loss: 0.0206\n",
            "#0945 | Loss: 0.0345\n",
            "#0946 | Loss: 0.0307\n",
            "#0947 | Loss: 0.0235\n",
            "#0948 | Loss: 0.0317\n",
            "#0949 | Loss: 0.0338\n",
            "#0950 | Loss: 0.0302\n",
            "#0951 | Loss: 0.0158\n",
            "#0952 | Loss: 0.0300\n",
            "#0953 | Loss: 0.0245\n",
            "#0954 | Loss: 0.0178\n",
            "#0955 | Loss: 0.0378\n",
            "#0956 | Loss: 0.0313\n",
            "#0957 | Loss: 0.0194\n",
            "#0958 | Loss: 0.0744\n",
            "#0959 | Loss: 0.0315\n",
            "#0960 | Loss: 0.0345\n",
            "#0961 | Loss: 0.0338\n",
            "#0962 | Loss: 0.0333\n",
            "#0963 | Loss: 0.0485\n",
            "#0964 | Loss: 0.0278\n",
            "#0965 | Loss: 0.0249\n",
            "#0966 | Loss: 0.0267\n",
            "#0967 | Loss: 0.0354\n",
            "#0968 | Loss: 0.0461\n",
            "#0969 | Loss: 0.0395\n",
            "#0970 | Loss: 0.0253\n",
            "#0971 | Loss: 0.0339\n",
            "#0972 | Loss: 0.0244\n",
            "#0973 | Loss: 0.0251\n",
            "#0974 | Loss: 0.0352\n",
            "#0975 | Loss: 0.0256\n",
            "#0976 | Loss: 0.0247\n",
            "#0977 | Loss: 0.0428\n",
            "#0978 | Loss: 0.0164\n",
            "#0979 | Loss: 0.0227\n",
            "#0980 | Loss: 0.0544\n",
            "#0981 | Loss: 0.0316\n",
            "#0982 | Loss: 0.0222\n",
            "#0983 | Loss: 0.0295\n",
            "#0984 | Loss: 0.0230\n",
            "#0985 | Loss: 0.0285\n",
            "#0986 | Loss: 0.0647\n",
            "#0987 | Loss: 0.0242\n",
            "#0988 | Loss: 0.0307\n",
            "#0989 | Loss: 0.0247\n",
            "#0990 | Loss: 0.0214\n",
            "#0991 | Loss: 0.0327\n",
            "#0992 | Loss: 0.0261\n",
            "#0993 | Loss: 0.0285\n",
            "#0994 | Loss: 0.0303\n",
            "#0995 | Loss: 0.0315\n",
            "#0996 | Loss: 0.0288\n",
            "#0997 | Loss: 0.0291\n",
            "#0998 | Loss: 0.0459\n",
            "#0999 | Loss: 0.0526\n",
            "#1000 | Loss: 0.0261\n",
            "#1001 | Loss: 0.0293\n",
            "#1002 | Loss: 0.0224\n",
            "#1003 | Loss: 0.0326\n",
            "#1004 | Loss: 0.0376\n",
            "#1005 | Loss: 0.0253\n",
            "#1006 | Loss: 0.0189\n",
            "#1007 | Loss: 0.0195\n",
            "#1008 | Loss: 0.0307\n",
            "#1009 | Loss: 0.0176\n",
            "#1010 | Loss: 0.0283\n",
            "#1011 | Loss: 0.0234\n",
            "#1012 | Loss: 0.0336\n",
            "#1013 | Loss: 0.0187\n",
            "#1014 | Loss: 0.0410\n",
            "#1015 | Loss: 0.0350\n",
            "#1016 | Loss: 0.0234\n",
            "#1017 | Loss: 0.0371\n",
            "#1018 | Loss: 0.0248\n",
            "#1019 | Loss: 0.0640\n",
            "#1020 | Loss: 0.0180\n",
            "#1021 | Loss: 0.0167\n",
            "#1022 | Loss: 0.0198\n",
            "#1023 | Loss: 0.0264\n",
            "#1024 | Loss: 0.0278\n",
            "#1025 | Loss: 0.0313\n",
            "#1026 | Loss: 0.0276\n",
            "#1027 | Loss: 0.0201\n",
            "#1028 | Loss: 0.0189\n",
            "#1029 | Loss: 0.0472\n",
            "#1030 | Loss: 0.0580\n",
            "#1031 | Loss: 0.0248\n",
            "#1032 | Loss: 0.0134\n",
            "#1033 | Loss: 0.0316\n",
            "#1034 | Loss: 0.0190\n",
            "#1035 | Loss: 0.0360\n",
            "#1036 | Loss: 0.0344\n",
            "#1037 | Loss: 0.0302\n",
            "#1038 | Loss: 0.0578\n",
            "#1039 | Loss: 0.0254\n",
            "#1040 | Loss: 0.0259\n",
            "#1041 | Loss: 0.0217\n",
            "#1042 | Loss: 0.0432\n",
            "#1043 | Loss: 0.0198\n",
            "#1044 | Loss: 0.0304\n",
            "#1045 | Loss: 0.0222\n",
            "#1046 | Loss: 0.0145\n",
            "#1047 | Loss: 0.0179\n",
            "#1048 | Loss: 0.0286\n",
            "#1049 | Loss: 0.0502\n",
            "#1050 | Loss: 0.0356\n",
            "#1051 | Loss: 0.0498\n",
            "#1052 | Loss: 0.0209\n",
            "#1053 | Loss: 0.0274\n",
            "#1054 | Loss: 0.0200\n",
            "#1055 | Loss: 0.0271\n",
            "#1056 | Loss: 0.0156\n",
            "#1057 | Loss: 0.0292\n",
            "#1058 | Loss: 0.0168\n",
            "#1059 | Loss: 0.0253\n",
            "#1060 | Loss: 0.0195\n",
            "#1061 | Loss: 0.0398\n",
            "#1062 | Loss: 0.0204\n",
            "#1063 | Loss: 0.0217\n",
            "#1064 | Loss: 0.0181\n",
            "#1065 | Loss: 0.0175\n",
            "#1066 | Loss: 0.0223\n",
            "#1067 | Loss: 0.0302\n",
            "#1068 | Loss: 0.0325\n",
            "#1069 | Loss: 0.0230\n",
            "#1070 | Loss: 0.0188\n",
            "#1071 | Loss: 0.0149\n",
            "#1072 | Loss: 0.0369\n",
            "#1073 | Loss: 0.0144\n",
            "#1074 | Loss: 0.0199\n",
            "#1075 | Loss: 0.0226\n",
            "#1076 | Loss: 0.0146\n",
            "#1077 | Loss: 0.0150\n",
            "#1078 | Loss: 0.0138\n",
            "#1079 | Loss: 0.0103\n",
            "#1080 | Loss: 0.0363\n",
            "#1081 | Loss: 0.0224\n",
            "#1082 | Loss: 0.0341\n",
            "#1083 | Loss: 0.0186\n",
            "#1084 | Loss: 0.0185\n",
            "#1085 | Loss: 0.0192\n",
            "#1086 | Loss: 0.0234\n",
            "#1087 | Loss: 0.0210\n",
            "#1088 | Loss: 0.0229\n",
            "#1089 | Loss: 0.0411\n",
            "#1090 | Loss: 0.0259\n",
            "#1091 | Loss: 0.0127\n",
            "#1092 | Loss: 0.0122\n",
            "#1093 | Loss: 0.0238\n",
            "#1094 | Loss: 0.0139\n",
            "#1095 | Loss: 0.0244\n",
            "#1096 | Loss: 0.0323\n",
            "#1097 | Loss: 0.0152\n",
            "#1098 | Loss: 0.0203\n",
            "#1099 | Loss: 0.0126\n",
            "#1100 | Loss: 0.0152\n",
            "#1101 | Loss: 0.0116\n",
            "#1102 | Loss: 0.0135\n",
            "#1103 | Loss: 0.0153\n",
            "#1104 | Loss: 0.0201\n",
            "#1105 | Loss: 0.0183\n",
            "#1106 | Loss: 0.0309\n",
            "#1107 | Loss: 0.0135\n",
            "#1108 | Loss: 0.0337\n",
            "#1109 | Loss: 0.0272\n",
            "#1110 | Loss: 0.0287\n",
            "#1111 | Loss: 0.0186\n",
            "#1112 | Loss: 0.0198\n",
            "#1113 | Loss: 0.0193\n",
            "#1114 | Loss: 0.0262\n",
            "#1115 | Loss: 0.0324\n",
            "#1116 | Loss: 0.0388\n",
            "#1117 | Loss: 0.0216\n",
            "#1118 | Loss: 0.0177\n",
            "#1119 | Loss: 0.0119\n",
            "#1120 | Loss: 0.0196\n",
            "#1121 | Loss: 0.0170\n",
            "#1122 | Loss: 0.0166\n",
            "#1123 | Loss: 0.0448\n",
            "#1124 | Loss: 0.0148\n",
            "#1125 | Loss: 0.0163\n",
            "#1126 | Loss: 0.0300\n",
            "#1127 | Loss: 0.0153\n",
            "#1128 | Loss: 0.0189\n",
            "#1129 | Loss: 0.0185\n",
            "#1130 | Loss: 0.0130\n",
            "#1131 | Loss: 0.0136\n",
            "#1132 | Loss: 0.0232\n",
            "#1133 | Loss: 0.0142\n",
            "#1134 | Loss: 0.0116\n",
            "#1135 | Loss: 0.0136\n",
            "#1136 | Loss: 0.0246\n",
            "#1137 | Loss: 0.0207\n",
            "#1138 | Loss: 0.0375\n",
            "#1139 | Loss: 0.0158\n",
            "#1140 | Loss: 0.0164\n",
            "#1141 | Loss: 0.0119\n",
            "#1142 | Loss: 0.0148\n",
            "#1143 | Loss: 0.0322\n",
            "#1144 | Loss: 0.0131\n",
            "#1145 | Loss: 0.0588\n",
            "#1146 | Loss: 0.0209\n",
            "#1147 | Loss: 0.0170\n",
            "#1148 | Loss: 0.0155\n",
            "#1149 | Loss: 0.0246\n",
            "#1150 | Loss: 0.0258\n",
            "#1151 | Loss: 0.0154\n",
            "#1152 | Loss: 0.0176\n",
            "#1153 | Loss: 0.0314\n",
            "#1154 | Loss: 0.0298\n",
            "#1155 | Loss: 0.0221\n",
            "#1156 | Loss: 0.0174\n",
            "#1157 | Loss: 0.0216\n",
            "#1158 | Loss: 0.0221\n",
            "#1159 | Loss: 0.0113\n",
            "#1160 | Loss: 0.0203\n",
            "#1161 | Loss: 0.0194\n",
            "#1162 | Loss: 0.0224\n",
            "#1163 | Loss: 0.0173\n",
            "#1164 | Loss: 0.0386\n",
            "#1165 | Loss: 0.0550\n",
            "#1166 | Loss: 0.0153\n",
            "#1167 | Loss: 0.0333\n",
            "#1168 | Loss: 0.0167\n",
            "#1169 | Loss: 0.0295\n",
            "#1170 | Loss: 0.0194\n",
            "#1171 | Loss: 0.0201\n",
            "#1172 | Loss: 0.0264\n",
            "#1173 | Loss: 0.0140\n",
            "#1174 | Loss: 0.0362\n",
            "#1175 | Loss: 0.0314\n",
            "#1176 | Loss: 0.0270\n",
            "#1177 | Loss: 0.0229\n",
            "#1178 | Loss: 0.0278\n",
            "#1179 | Loss: 0.0279\n",
            "#1180 | Loss: 0.0158\n",
            "#1181 | Loss: 0.0304\n",
            "#1182 | Loss: 0.0273\n",
            "#1183 | Loss: 0.0200\n",
            "#1184 | Loss: 0.0139\n",
            "#1185 | Loss: 0.0126\n",
            "#1186 | Loss: 0.0225\n",
            "#1187 | Loss: 0.0222\n",
            "#1188 | Loss: 0.0145\n",
            "#1189 | Loss: 0.0192\n",
            "#1190 | Loss: 0.0250\n",
            "#1191 | Loss: 0.0331\n",
            "#1192 | Loss: 0.0420\n",
            "#1193 | Loss: 0.0128\n",
            "#1194 | Loss: 0.0118\n",
            "#1195 | Loss: 0.0353\n",
            "#1196 | Loss: 0.0161\n",
            "#1197 | Loss: 0.0161\n",
            "#1198 | Loss: 0.0127\n",
            "#1199 | Loss: 0.0150\n",
            "#1200 | Loss: 0.0189\n",
            "#1201 | Loss: 0.0226\n",
            "#1202 | Loss: 0.0166\n",
            "#1203 | Loss: 0.0288\n",
            "#1204 | Loss: 0.0209\n",
            "#1205 | Loss: 0.0179\n",
            "#1206 | Loss: 0.0188\n",
            "#1207 | Loss: 0.0186\n",
            "#1208 | Loss: 0.0301\n",
            "#1209 | Loss: 0.0170\n",
            "#1210 | Loss: 0.0139\n",
            "#1211 | Loss: 0.0132\n",
            "#1212 | Loss: 0.0377\n",
            "#1213 | Loss: 0.0265\n",
            "#1214 | Loss: 0.0147\n",
            "#1215 | Loss: 0.0176\n",
            "#1216 | Loss: 0.0161\n",
            "#1217 | Loss: 0.0271\n",
            "#1218 | Loss: 0.0224\n",
            "#1219 | Loss: 0.0130\n",
            "#1220 | Loss: 0.0175\n",
            "#1221 | Loss: 0.0187\n",
            "#1222 | Loss: 0.0318\n",
            "#1223 | Loss: 0.0147\n",
            "#1224 | Loss: 0.0101\n",
            "#1225 | Loss: 0.0215\n",
            "#1226 | Loss: 0.0233\n",
            "#1227 | Loss: 0.0103\n",
            "#1228 | Loss: 0.0148\n",
            "#1229 | Loss: 0.0118\n",
            "#1230 | Loss: 0.0110\n",
            "#1231 | Loss: 0.0294\n",
            "#1232 | Loss: 0.0262\n",
            "#1233 | Loss: 0.0139\n",
            "#1234 | Loss: 0.0182\n",
            "#1235 | Loss: 0.0142\n",
            "#1236 | Loss: 0.0267\n",
            "#1237 | Loss: 0.0121\n",
            "#1238 | Loss: 0.0141\n",
            "#1239 | Loss: 0.0128\n",
            "#1240 | Loss: 0.0149\n",
            "#1241 | Loss: 0.0322\n",
            "#1242 | Loss: 0.0162\n",
            "#1243 | Loss: 0.0171\n",
            "#1244 | Loss: 0.0190\n",
            "#1245 | Loss: 0.0276\n",
            "#1246 | Loss: 0.0173\n",
            "#1247 | Loss: 0.0230\n",
            "#1248 | Loss: 0.0257\n",
            "#1249 | Loss: 0.0185\n",
            "#1250 | Loss: 0.0281\n",
            "#1251 | Loss: 0.0238\n",
            "#1252 | Loss: 0.0189\n",
            "#1253 | Loss: 0.0127\n",
            "#1254 | Loss: 0.0168\n",
            "#1255 | Loss: 0.0267\n",
            "#1256 | Loss: 0.0259\n",
            "#1257 | Loss: 0.0275\n",
            "#1258 | Loss: 0.0224\n",
            "#1259 | Loss: 0.0227\n",
            "#1260 | Loss: 0.0172\n",
            "#1261 | Loss: 0.0216\n",
            "#1262 | Loss: 0.0236\n",
            "#1263 | Loss: 0.0288\n",
            "#1264 | Loss: 0.0330\n",
            "#1265 | Loss: 0.0142\n",
            "#1266 | Loss: 0.0137\n",
            "#1267 | Loss: 0.0162\n",
            "#1268 | Loss: 0.0157\n",
            "#1269 | Loss: 0.0125\n",
            "#1270 | Loss: 0.0199\n",
            "#1271 | Loss: 0.0148\n",
            "#1272 | Loss: 0.0214\n",
            "#1273 | Loss: 0.0157\n",
            "#1274 | Loss: 0.0219\n",
            "#1275 | Loss: 0.0225\n",
            "#1276 | Loss: 0.0154\n",
            "#1277 | Loss: 0.0135\n",
            "#1278 | Loss: 0.0219\n",
            "#1279 | Loss: 0.0125\n",
            "#1280 | Loss: 0.0168\n",
            "#1281 | Loss: 0.0246\n",
            "#1282 | Loss: 0.0180\n",
            "#1283 | Loss: 0.0130\n",
            "#1284 | Loss: 0.0111\n",
            "#1285 | Loss: 0.0189\n",
            "#1286 | Loss: 0.0222\n",
            "#1287 | Loss: 0.0080\n",
            "#1288 | Loss: 0.0399\n",
            "#1289 | Loss: 0.0135\n",
            "#1290 | Loss: 0.0320\n",
            "#1291 | Loss: 0.0149\n",
            "#1292 | Loss: 0.0141\n",
            "#1293 | Loss: 0.0074\n",
            "#1294 | Loss: 0.0166\n",
            "#1295 | Loss: 0.0108\n",
            "#1296 | Loss: 0.0110\n",
            "#1297 | Loss: 0.0182\n",
            "#1298 | Loss: 0.0086\n",
            "#1299 | Loss: 0.0158\n",
            "#1300 | Loss: 0.0273\n",
            "#1301 | Loss: 0.0180\n",
            "#1302 | Loss: 0.0320\n",
            "#1303 | Loss: 0.0201\n",
            "#1304 | Loss: 0.0278\n",
            "#1305 | Loss: 0.0220\n",
            "#1306 | Loss: 0.0242\n",
            "#1307 | Loss: 0.0126\n",
            "#1308 | Loss: 0.0445\n",
            "#1309 | Loss: 0.0181\n",
            "#1310 | Loss: 0.0133\n",
            "#1311 | Loss: 0.0207\n",
            "#1312 | Loss: 0.0318\n",
            "#1313 | Loss: 0.0408\n",
            "#1314 | Loss: 0.0147\n",
            "#1315 | Loss: 0.0182\n",
            "#1316 | Loss: 0.0254\n",
            "#1317 | Loss: 0.0420\n",
            "#1318 | Loss: 0.0177\n",
            "#1319 | Loss: 0.0165\n",
            "#1320 | Loss: 0.0236\n",
            "#1321 | Loss: 0.0195\n",
            "#1322 | Loss: 0.0123\n",
            "#1323 | Loss: 0.0401\n",
            "#1324 | Loss: 0.0125\n",
            "#1325 | Loss: 0.0239\n",
            "#1326 | Loss: 0.0366\n",
            "#1327 | Loss: 0.0183\n",
            "#1328 | Loss: 0.0213\n",
            "#1329 | Loss: 0.0274\n",
            "#1330 | Loss: 0.0160\n",
            "#1331 | Loss: 0.0463\n",
            "#1332 | Loss: 0.0320\n",
            "#1333 | Loss: 0.0172\n",
            "#1334 | Loss: 0.0198\n",
            "#1335 | Loss: 0.0221\n",
            "#1336 | Loss: 0.0132\n",
            "#1337 | Loss: 0.0345\n",
            "#1338 | Loss: 0.0360\n",
            "#1339 | Loss: 0.0430\n",
            "#1340 | Loss: 0.0498\n",
            "#1341 | Loss: 0.0446\n",
            "#1342 | Loss: 0.0265\n",
            "#1343 | Loss: 0.0319\n",
            "#1344 | Loss: 0.0328\n",
            "#1345 | Loss: 0.0193\n",
            "#1346 | Loss: 0.0300\n",
            "#1347 | Loss: 0.0265\n",
            "#1348 | Loss: 0.0166\n",
            "#1349 | Loss: 0.0241\n",
            "#1350 | Loss: 0.0241\n",
            "#1351 | Loss: 0.0182\n",
            "#1352 | Loss: 0.0586\n",
            "#1353 | Loss: 0.0392\n",
            "#1354 | Loss: 0.0185\n",
            "#1355 | Loss: 0.0149\n",
            "#1356 | Loss: 0.0187\n",
            "#1357 | Loss: 0.0281\n",
            "#1358 | Loss: 0.0231\n",
            "#1359 | Loss: 0.0651\n",
            "#1360 | Loss: 0.0257\n",
            "#1361 | Loss: 0.0266\n",
            "#1362 | Loss: 0.0215\n",
            "#1363 | Loss: 0.0291\n",
            "#1364 | Loss: 0.0274\n",
            "#1365 | Loss: 0.0196\n",
            "#1366 | Loss: 0.0248\n",
            "#1367 | Loss: 0.0232\n",
            "#1368 | Loss: 0.0207\n",
            "#1369 | Loss: 0.0231\n",
            "#1370 | Loss: 0.0333\n",
            "#1371 | Loss: 0.0264\n",
            "#1372 | Loss: 0.0241\n",
            "#1373 | Loss: 0.0366\n",
            "#1374 | Loss: 0.0322\n",
            "#1375 | Loss: 0.0281\n",
            "#1376 | Loss: 0.0330\n",
            "#1377 | Loss: 0.0240\n",
            "#1378 | Loss: 0.0161\n",
            "#1379 | Loss: 0.0212\n",
            "#1380 | Loss: 0.0216\n",
            "#1381 | Loss: 0.0461\n",
            "#1382 | Loss: 0.0891\n",
            "#1383 | Loss: 0.0278\n",
            "#1384 | Loss: 0.0153\n",
            "#1385 | Loss: 0.0128\n",
            "#1386 | Loss: 0.0313\n",
            "#1387 | Loss: 0.0392\n",
            "#1388 | Loss: 0.0419\n",
            "#1389 | Loss: 0.0248\n",
            "#1390 | Loss: 0.0276\n",
            "#1391 | Loss: 0.0296\n",
            "#1392 | Loss: 0.0230\n",
            "#1393 | Loss: 0.0336\n",
            "#1394 | Loss: 0.0213\n",
            "#1395 | Loss: 0.0192\n",
            "#1396 | Loss: 0.0166\n",
            "#1397 | Loss: 0.0318\n",
            "#1398 | Loss: 0.0160\n",
            "#1399 | Loss: 0.0275\n",
            "#1400 | Loss: 0.0212\n",
            "#1401 | Loss: 0.0258\n",
            "#1402 | Loss: 0.0330\n",
            "#1403 | Loss: 0.0200\n",
            "#1404 | Loss: 0.0145\n",
            "#1405 | Loss: 0.0165\n",
            "#1406 | Loss: 0.0204\n",
            "#1407 | Loss: 0.0208\n",
            "#1408 | Loss: 0.0161\n",
            "#1409 | Loss: 0.0139\n",
            "#1410 | Loss: 0.0184\n",
            "#1411 | Loss: 0.0209\n",
            "#1412 | Loss: 0.0152\n",
            "#1413 | Loss: 0.0333\n",
            "#1414 | Loss: 0.0183\n",
            "#1415 | Loss: 0.0373\n",
            "#1416 | Loss: 0.0136\n",
            "#1417 | Loss: 0.0133\n",
            "#1418 | Loss: 0.0204\n",
            "#1419 | Loss: 0.0196\n",
            "#1420 | Loss: 0.0169\n",
            "#1421 | Loss: 0.0195\n",
            "#1422 | Loss: 0.0143\n",
            "#1423 | Loss: 0.0154\n",
            "#1424 | Loss: 0.0131\n",
            "#1425 | Loss: 0.0169\n",
            "#1426 | Loss: 0.0080\n",
            "#1427 | Loss: 0.0171\n",
            "#1428 | Loss: 0.0274\n",
            "#1429 | Loss: 0.0307\n",
            "#1430 | Loss: 0.0217\n",
            "#1431 | Loss: 0.0156\n",
            "#1432 | Loss: 0.0126\n",
            "#1433 | Loss: 0.0254\n",
            "#1434 | Loss: 0.0134\n",
            "#1435 | Loss: 0.0193\n",
            "#1436 | Loss: 0.0269\n",
            "#1437 | Loss: 0.0149\n",
            "#1438 | Loss: 0.0166\n",
            "#1439 | Loss: 0.0182\n",
            "#1440 | Loss: 0.0316\n",
            "#1441 | Loss: 0.0085\n",
            "#1442 | Loss: 0.0116\n",
            "#1443 | Loss: 0.0176\n",
            "#1444 | Loss: 0.0151\n",
            "#1445 | Loss: 0.0089\n",
            "#1446 | Loss: 0.0162\n",
            "#1447 | Loss: 0.0098\n",
            "#1448 | Loss: 0.0062\n",
            "#1449 | Loss: 0.0132\n",
            "#1450 | Loss: 0.0153\n",
            "#1451 | Loss: 0.0092\n",
            "#1452 | Loss: 0.0111\n",
            "#1453 | Loss: 0.0216\n",
            "#1454 | Loss: 0.0182\n",
            "#1455 | Loss: 0.0117\n",
            "#1456 | Loss: 0.0071\n",
            "#1457 | Loss: 0.0213\n",
            "#1458 | Loss: 0.0127\n",
            "#1459 | Loss: 0.0145\n",
            "#1460 | Loss: 0.0104\n",
            "#1461 | Loss: 0.0104\n",
            "#1462 | Loss: 0.0147\n",
            "#1463 | Loss: 0.0150\n",
            "#1464 | Loss: 0.0132\n",
            "#1465 | Loss: 0.0186\n",
            "#1466 | Loss: 0.0223\n",
            "#1467 | Loss: 0.0402\n",
            "#1468 | Loss: 0.0129\n",
            "#1469 | Loss: 0.0127\n",
            "#1470 | Loss: 0.0121\n",
            "#1471 | Loss: 0.0146\n",
            "#1472 | Loss: 0.0105\n",
            "#1473 | Loss: 0.0125\n",
            "#1474 | Loss: 0.0120\n",
            "#1475 | Loss: 0.0216\n",
            "#1476 | Loss: 0.0156\n",
            "#1477 | Loss: 0.0182\n",
            "#1478 | Loss: 0.0124\n",
            "#1479 | Loss: 0.0136\n",
            "#1480 | Loss: 0.0128\n",
            "#1481 | Loss: 0.0092\n",
            "#1482 | Loss: 0.0163\n",
            "#1483 | Loss: 0.0144\n",
            "#1484 | Loss: 0.0155\n",
            "#1485 | Loss: 0.0143\n",
            "#1486 | Loss: 0.0080\n",
            "#1487 | Loss: 0.0450\n",
            "#1488 | Loss: 0.0162\n",
            "#1489 | Loss: 0.0170\n",
            "#1490 | Loss: 0.0225\n",
            "#1491 | Loss: 0.0188\n",
            "#1492 | Loss: 0.0186\n",
            "#1493 | Loss: 0.0096\n",
            "#1494 | Loss: 0.0137\n",
            "#1495 | Loss: 0.0070\n",
            "#1496 | Loss: 0.0110\n",
            "#1497 | Loss: 0.0132\n",
            "#1498 | Loss: 0.0135\n",
            "#1499 | Loss: 0.0128\n",
            "#1500 | Loss: 0.0135\n",
            "X00016469670\n",
            "X00016469671\n",
            "X51005200931\n",
            "X51005230605\n",
            "X51005230616\n",
            "X51005230621\n",
            "X51005230648\n",
            "X51005230657\n",
            "X51005230659\n",
            "X51005268275\n",
            "X51005268408\n",
            "X51005288570\n",
            "X51005301666\n",
            "X51005337867\n",
            "X51005337877\n",
            "X51005361906\n",
            "X51005361908\n",
            "X51005361912\n",
            "X51005361923\n",
            "X51005365187\n",
            "X51005433518\n",
            "X51005433543\n",
            "X51005433548\n",
            "X51005433556\n",
            "X51005442322\n",
            "X51005442334\n",
            "X51005442343\n",
            "X51005442366\n",
            "X51005442375\n",
            "X51005442382\n",
            "X51005442388\n",
            "X51005444040\n",
            "X51005444041\n",
            "X51005444044\n",
            "X51005444046\n",
            "X51005447841\n",
            "X51005447842\n",
            "X51005447844\n",
            "X51005447851\n",
            "X51005447859\n",
            "X51005568855\n",
            "X51005568866\n",
            "X51005568885\n",
            "X51005568887\n",
            "X51005568889\n",
            "X51005568890\n",
            "X51005568892\n",
            "X51005568894\n",
            "X51005568895\n",
            "X51005577191\n",
            "X51005582745\n",
            "X51005587261\n",
            "X51005605287\n",
            "X51005605295\n",
            "X51005605332\n",
            "X51005621482\n",
            "X51005663274\n",
            "X51005663300\n",
            "X51005663307\n",
            "X51005663309\n",
            "X51005663310\n",
            "X51005663323\n",
            "X51005675099\n",
            "X51005675103\n",
            "X51005675104\n",
            "X51005675914\n",
            "X51005676534\n",
            "X51005676535\n",
            "X51005676537\n",
            "X51005676542\n",
            "X51005676548\n",
            "X51005677327\n",
            "X51005677333\n",
            "X51005677336\n",
            "X51005677337\n",
            "X510056849111\n",
            "X51005684949\n",
            "X51005705727\n",
            "X51005705729\n",
            "X51005705784\n",
            "X51005710963\n",
            "X51005711402\n",
            "X51005711443\n",
            "X51005711444\n",
            "X51005711446\n",
            "X51005711449\n",
            "X51005715007\n",
            "X51005715455\n",
            "X51005719823\n",
            "X51005719855\n",
            "X51005719857\n",
            "X51005719863\n",
            "X51005719888\n",
            "X51005719889\n",
            "X51005719895\n",
            "X51005719898\n",
            "X51005719903\n",
            "X51005719905\n",
            "X51005724552\n",
            "X51005724611\n",
            "X51005724622\n",
            "X51005724623\n",
            "X51005724624\n",
            "X51005724625\n",
            "X51005724626\n",
            "X51005724628\n",
            "X51005741929\n",
            "X51005742110\n",
            "X51005745213\n",
            "X51005745244\n",
            "X51005745298\n",
            "X51005746203\n",
            "X51005746204\n",
            "X51005746206\n",
            "X51005746207\n",
            "X51005746210\n",
            "X51005749904\n",
            "X51005757233\n",
            "X51005757282\n",
            "X51005757292\n",
            "X51005757308\n",
            "X51005757342\n",
            "X51005763958\n",
            "X51005763964\n",
            "X51005763999\n",
            "X51005764031\n",
            "X51005764154\n",
            "X51005764161\n",
            "X51005806692\n",
            "X51005806695\n",
            "X51005806696\n",
            "X51005806718\n",
            "X51005806719\n",
            "X51005806720\n",
            "X51006008081\n",
            "X51006008082\n",
            "X51006008083\n",
            "X51006008090\n",
            "X51006008092\n",
            "X51006008093\n",
            "X51006008105\n",
            "X51006008166\n",
            "X51006008206\n",
            "X51006248253\n",
            "X51006311714\n",
            "X51006327953\n",
            "X51006327960\n",
            "X51006328345\n",
            "X51006328937\n",
            "X51006328967\n",
            "X51006329183\n",
            "X51006329388\n",
            "X51006332641\n",
            "X51006334139\n",
            "X51006334742\n",
            "X51006334766\n",
            "X51006334770\n",
            "X51006334819\n",
            "X51006334927\n",
            "X51006335818\n",
            "X51006349081\n",
            "X51006349083\n",
            "X51006349085\n",
            "X51006350737\n",
            "X51006387660\n",
            "X51006387737\n",
            "X51006387931\n",
            "X51006387950\n",
            "X51006387973\n",
            "X51006388068\n",
            "X51006388081\n",
            "X51006388089\n",
            "X51006389894\n",
            "X51006389898\n",
            "X51006392167\n",
            "X51006401845\n",
            "X51006401853\n",
            "X51006401977\n",
            "X51006414425\n",
            "X51006414427\n",
            "X51006414433\n",
            "X51006414512\n",
            "X51006414532\n",
            "X51006414593\n",
            "X51006414600\n",
            "X51006414702\n",
            "X51006414708\n",
            "X51006414715\n",
            "X51006414717\n",
            "X51006414728\n",
            "X51006438346\n",
            "X51006466070\n",
            "X51006502534\n",
            "X51006502540\n",
            "X51006554841\n",
            "X51006555819\n",
            "X51006555833\n",
            "X51006555835\n",
            "X51006556610\n",
            "X51006556648\n",
            "X51006556654\n",
            "X51006556657\n",
            "X51006556658\n",
            "X51006556723\n",
            "X51006556728\n",
            "X51006556734\n",
            "X51006556740\n",
            "X51006556806\n",
            "X51006556808\n",
            "X51006556809\n",
            "X51006556810\n",
            "X51006556812\n",
            "X51006556821\n",
            "X51006556826\n",
            "X51006556827\n",
            "X51006556829\n",
            "X51006556851\n",
            "X51006556865\n",
            "X51006557115\n",
            "X51006557169\n",
            "X51006557173\n",
            "X51006557187\n",
            "X51006557194\n",
            "X51006557196\n",
            "X51006557208\n",
            "X51006557209\n",
            "X51006557507\n",
            "X51006619328\n",
            "X51006619338\n",
            "X51006619346\n",
            "X51006619503\n",
            "X51006619506\n",
            "X51006619507\n",
            "X51006619509\n",
            "X51006619564\n",
            "X51006619567\n",
            "X51006619569\n",
            "X51006619570\n",
            "X51006619700\n",
            "X51006619703\n",
            "X51006619704\n",
            "X51006619757\n",
            "X51006619760\n",
            "X51006619764\n",
            "X51006619766\n",
            "X51006619779\n",
            "X51006619784\n",
            "X51006619790\n",
            "X51006619842\n",
            "X51006619863\n",
            "X51006619869\n",
            "X51006620175\n",
            "X51006620182\n",
            "X51006620192\n",
            "X51006620437\n",
            "X51006647933\n",
            "X51006647984\n",
            "X51006733495\n",
            "X51006828199\n",
            "X51006828200\n",
            "X51006828201\n",
            "X51006856982\n",
            "X51006857126\n",
            "X51006857132\n",
            "X51006857137\n",
            "X51006857540\n",
            "X51006912959\n",
            "X51006912976\n",
            "X51006912998\n",
            "X51006913018\n",
            "X51006913032\n",
            "X51006913060\n",
            "X51006913061\n",
            "X51007103597\n",
            "X51007103610\n",
            "X51007103649\n",
            "X51007103668\n",
            "X51007103687\n",
            "X51007225406\n",
            "X51007231274\n",
            "X51007231275\n",
            "X51007231276\n",
            "X51007231331\n",
            "X51007231341\n",
            "X51007231343\n",
            "X51007231346\n",
            "X51007231364\n",
            "X51007231372\n",
            "X51007339105\n",
            "X51007339109\n",
            "X51007339116\n",
            "X51007339119\n",
            "X51007339121\n",
            "X51007339122\n",
            "X51007339125\n",
            "X51007339127\n",
            "X51007339134\n",
            "X51007339159\n",
            "X51007339160\n",
            "X51007339161\n",
            "X51007339163\n",
            "X51007339638\n",
            "X51007391390\n",
            "X51007433809\n",
            "X51007579714\n",
            "X51007579719\n",
            "X51007579725\n",
            "X51007846266\n",
            "X51007846268\n",
            "X51007846282\n",
            "X51007846283\n",
            "X51007846288\n",
            "X51007846289\n",
            "X51007846290\n",
            "X51007846303\n",
            "X51007846304\n",
            "X51007846310\n",
            "X51007846321\n",
            "X51007846355\n",
            "X51007846358\n",
            "X51007846360\n",
            "X51007846361\n",
            "X51007846371\n",
            "X51007846372\n",
            "X51007846379\n",
            "X51007846387\n",
            "X51007846392\n",
            "X51007846396\n",
            "X51007846397\n",
            "X51007846400\n",
            "X51007846403\n",
            "X51008030561\n",
            "X51008030563\n",
            "X51008042779\n",
            "X51008042780\n",
            "X51008042781\n",
            "X51008042786\n",
            "X51008042787\n",
            "X51008099047\n",
            "X51008099086\n",
            "X51008099088\n",
            "X51008099090\n",
            "X51008099100\n",
            "X51009008095\n",
            "X51009447842\n",
            "X51009453729\n",
            "X51009568881\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qgeO8EXBLMv",
        "outputId": "0c0f567c-8c28-41a2-b7d2-d9f84dc34120"
      },
      "source": [
        "!python /content/ICDAR-2019-SROIE/task3/src/test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X00016469670\n",
            "X00016469671\n",
            "X51005200931\n",
            "X51005230605\n",
            "X51005230616\n",
            "X51005230621\n",
            "X51005230648\n",
            "X51005230657\n",
            "X51005230659\n",
            "X51005268275\n",
            "X51005268408\n",
            "X51005288570\n",
            "X51005301666\n",
            "X51005337867\n",
            "X51005337877\n",
            "X51005361906\n",
            "X51005361908\n",
            "X51005361912\n",
            "X51005361923\n",
            "X51005365187\n",
            "X51005433518\n",
            "X51005433543\n",
            "X51005433548\n",
            "X51005433556\n",
            "X51005442322\n",
            "X51005442334\n",
            "X51005442343\n",
            "X51005442366\n",
            "X51005442375\n",
            "X51005442382\n",
            "X51005442388\n",
            "X51005444040\n",
            "X51005444041\n",
            "X51005444044\n",
            "X51005444046\n",
            "X51005447841\n",
            "X51005447842\n",
            "X51005447844\n",
            "X51005447851\n",
            "X51005447859\n",
            "X51005568855\n",
            "X51005568866\n",
            "X51005568885\n",
            "X51005568887\n",
            "X51005568889\n",
            "X51005568890\n",
            "X51005568892\n",
            "X51005568894\n",
            "X51005568895\n",
            "X51005577191\n",
            "X51005582745\n",
            "X51005587261\n",
            "X51005605287\n",
            "X51005605295\n",
            "X51005605332\n",
            "X51005621482\n",
            "X51005663274\n",
            "X51005663300\n",
            "X51005663307\n",
            "X51005663309\n",
            "X51005663310\n",
            "X51005663323\n",
            "X51005675099\n",
            "X51005675103\n",
            "X51005675104\n",
            "X51005675914\n",
            "X51005676534\n",
            "X51005676535\n",
            "X51005676537\n",
            "X51005676542\n",
            "X51005676548\n",
            "X51005677327\n",
            "X51005677333\n",
            "X51005677336\n",
            "X51005677337\n",
            "X510056849111\n",
            "X51005684949\n",
            "X51005705727\n",
            "X51005705729\n",
            "X51005705784\n",
            "X51005710963\n",
            "X51005711402\n",
            "X51005711443\n",
            "X51005711444\n",
            "X51005711446\n",
            "X51005711449\n",
            "X51005715007\n",
            "X51005715455\n",
            "X51005719823\n",
            "X51005719855\n",
            "X51005719857\n",
            "X51005719863\n",
            "X51005719888\n",
            "X51005719889\n",
            "X51005719895\n",
            "X51005719898\n",
            "X51005719903\n",
            "X51005719905\n",
            "X51005724552\n",
            "X51005724611\n",
            "X51005724622\n",
            "X51005724623\n",
            "X51005724624\n",
            "X51005724625\n",
            "X51005724626\n",
            "X51005724628\n",
            "X51005741929\n",
            "X51005742110\n",
            "X51005745213\n",
            "X51005745244\n",
            "X51005745298\n",
            "X51005746203\n",
            "X51005746204\n",
            "X51005746206\n",
            "X51005746207\n",
            "X51005746210\n",
            "X51005749904\n",
            "X51005757233\n",
            "X51005757282\n",
            "X51005757292\n",
            "X51005757308\n",
            "X51005757342\n",
            "X51005763958\n",
            "X51005763964\n",
            "X51005763999\n",
            "X51005764031\n",
            "X51005764154\n",
            "X51005764161\n",
            "X51005806692\n",
            "X51005806695\n",
            "X51005806696\n",
            "X51005806718\n",
            "X51005806719\n",
            "X51005806720\n",
            "X51006008081\n",
            "X51006008082\n",
            "X51006008083\n",
            "X51006008090\n",
            "X51006008092\n",
            "X51006008093\n",
            "X51006008105\n",
            "X51006008166\n",
            "X51006008206\n",
            "X51006248253\n",
            "X51006311714\n",
            "X51006327953\n",
            "X51006327960\n",
            "X51006328345\n",
            "X51006328937\n",
            "X51006328967\n",
            "X51006329183\n",
            "X51006329388\n",
            "X51006332641\n",
            "X51006334139\n",
            "X51006334742\n",
            "X51006334766\n",
            "X51006334770\n",
            "X51006334819\n",
            "X51006334927\n",
            "X51006335818\n",
            "X51006349081\n",
            "X51006349083\n",
            "X51006349085\n",
            "X51006350737\n",
            "X51006387660\n",
            "X51006387737\n",
            "X51006387931\n",
            "X51006387950\n",
            "X51006387973\n",
            "X51006388068\n",
            "X51006388081\n",
            "X51006388089\n",
            "X51006389894\n",
            "X51006389898\n",
            "X51006392167\n",
            "X51006401845\n",
            "X51006401853\n",
            "X51006401977\n",
            "X51006414425\n",
            "X51006414427\n",
            "X51006414433\n",
            "X51006414512\n",
            "X51006414532\n",
            "X51006414593\n",
            "X51006414600\n",
            "X51006414702\n",
            "X51006414708\n",
            "X51006414715\n",
            "X51006414717\n",
            "X51006414728\n",
            "X51006438346\n",
            "X51006466070\n",
            "X51006502534\n",
            "X51006502540\n",
            "X51006554841\n",
            "X51006555819\n",
            "X51006555833\n",
            "X51006555835\n",
            "X51006556610\n",
            "X51006556648\n",
            "X51006556654\n",
            "X51006556657\n",
            "X51006556658\n",
            "X51006556723\n",
            "X51006556728\n",
            "X51006556734\n",
            "X51006556740\n",
            "X51006556806\n",
            "X51006556808\n",
            "X51006556809\n",
            "X51006556810\n",
            "X51006556812\n",
            "X51006556821\n",
            "X51006556826\n",
            "X51006556827\n",
            "X51006556829\n",
            "X51006556851\n",
            "X51006556865\n",
            "X51006557115\n",
            "X51006557169\n",
            "X51006557173\n",
            "X51006557187\n",
            "X51006557194\n",
            "X51006557196\n",
            "X51006557208\n",
            "X51006557209\n",
            "X51006557507\n",
            "X51006619328\n",
            "X51006619338\n",
            "X51006619346\n",
            "X51006619503\n",
            "X51006619506\n",
            "X51006619507\n",
            "X51006619509\n",
            "X51006619564\n",
            "X51006619567\n",
            "X51006619569\n",
            "X51006619570\n",
            "X51006619700\n",
            "X51006619703\n",
            "X51006619704\n",
            "X51006619757\n",
            "X51006619760\n",
            "X51006619764\n",
            "X51006619766\n",
            "X51006619779\n",
            "X51006619784\n",
            "X51006619790\n",
            "X51006619842\n",
            "X51006619863\n",
            "X51006619869\n",
            "X51006620175\n",
            "X51006620182\n",
            "X51006620192\n",
            "X51006620437\n",
            "X51006647933\n",
            "X51006647984\n",
            "X51006733495\n",
            "X51006828199\n",
            "X51006828200\n",
            "X51006828201\n",
            "X51006856982\n",
            "X51006857126\n",
            "X51006857132\n",
            "X51006857137\n",
            "X51006857540\n",
            "X51006912959\n",
            "X51006912976\n",
            "X51006912998\n",
            "X51006913018\n",
            "X51006913032\n",
            "X51006913060\n",
            "X51006913061\n",
            "X51007103597\n",
            "X51007103610\n",
            "X51007103649\n",
            "X51007103668\n",
            "X51007103687\n",
            "X51007225406\n",
            "X51007231274\n",
            "X51007231275\n",
            "X51007231276\n",
            "X51007231331\n",
            "X51007231341\n",
            "X51007231343\n",
            "X51007231346\n",
            "X51007231364\n",
            "X51007231372\n",
            "X51007339105\n",
            "X51007339109\n",
            "X51007339116\n",
            "X51007339119\n",
            "X51007339121\n",
            "X51007339122\n",
            "X51007339125\n",
            "X51007339127\n",
            "X51007339134\n",
            "X51007339159\n",
            "X51007339160\n",
            "X51007339161\n",
            "X51007339163\n",
            "X51007339638\n",
            "X51007391390\n",
            "X51007433809\n",
            "X51007579714\n",
            "X51007579719\n",
            "X51007579725\n",
            "X51007846266\n",
            "X51007846268\n",
            "X51007846282\n",
            "X51007846283\n",
            "X51007846288\n",
            "X51007846289\n",
            "X51007846290\n",
            "X51007846303\n",
            "X51007846304\n",
            "X51007846310\n",
            "X51007846321\n",
            "X51007846355\n",
            "X51007846358\n",
            "X51007846360\n",
            "X51007846361\n",
            "X51007846371\n",
            "X51007846372\n",
            "X51007846379\n",
            "X51007846387\n",
            "X51007846392\n",
            "X51007846396\n",
            "X51007846397\n",
            "X51007846400\n",
            "X51007846403\n",
            "X51008030561\n",
            "X51008030563\n",
            "X51008042779\n",
            "X51008042780\n",
            "X51008042781\n",
            "X51008042786\n",
            "X51008042787\n",
            "X51008099047\n",
            "X51008099086\n",
            "X51008099088\n",
            "X51008099090\n",
            "X51008099100\n",
            "X51009008095\n",
            "X51009447842\n",
            "X51009453729\n",
            "X51009568881\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}